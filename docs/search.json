[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GRAPH Sommerakdemie 24",
    "section": "",
    "text": "Willkommen üëã!\nHier finden sich\n\nErkl√§rungen,\nVideos,\nAufgaben,\nDaten und\nCode\n\nf√ºr unseren Kurs Bayesian Regression Modelling.\nZu Beginn des Kurses bitte ich alle eine aktuelle Version von  und Studio installiert zu haben und au√üerdem - falls noch nicht mit {brms} gearbeitet wurde - dieser Anleitung zur Installation und Verkn√ºpfung des -Paketes {brms} zu folgen. Bei Problemen bitte gerne bei mir vorab melden!",
    "crumbs": [
      "Willkommen üëã!"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html",
    "href": "grundlegende_begriffe.html",
    "title": "1¬† Grundlegende Begriffe",
    "section": "",
    "text": "1.1 Wahrscheinlichkeitsbegriff von Laplace\nDie mathematische Wahrscheinlichkeitstheorie (Stochastik) ist ein vergleichsweise junge Subdisziplin, die erst zu Beginn des 20. Jahrhunderts axiomatisch formalisiert wurde. in diesen Ans√§tzen definiert man Wahrscheinlichkeitsma√üe z.B. durch die folgenden Axiome.\nDas ist weder besonders intuitiv noch hilfreich f√ºr die Anwendung in der Datenanalyse. Eine wichtige Kontextinfromation k√∂nnte jedoch sein, dass die Wahrscheinlichkeitsrechnung bis ins 19. Jhd. hinein vor allem als Hilfsmittel f√ºr Gl√ºcksspiele und Wetten entwickelt wurde. In diesem Kontext ist es recht hilfreich und intuitiv Wahrscheinlichkeit als relative H√§ufigkeit zu verstehen. So findet man auch etwa in Mathematikb√ºchern der 7.ten Klasse Aussagen wie",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#wahrscheinlichkeitsbegriff-von-laplace",
    "href": "grundlegende_begriffe.html#wahrscheinlichkeitsbegriff-von-laplace",
    "title": "1¬† Grundlegende Begriffe",
    "section": "",
    "text": "‚ÄúDie Wahrscheinlichkeit, dass eine gerade Zahl gew√ºrfelt wird, betr√§gt 3/6, denn es gibt 6 m√∂gliche Ergebnisse und drei g√ºnstige.‚Äù",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#stochastik-vs.-statistik",
    "href": "grundlegende_begriffe.html#stochastik-vs.-statistik",
    "title": "1¬† Grundlegende Begriffe",
    "section": "1.2 Stochastik vs.¬†Statistik",
    "text": "1.2 Stochastik vs.¬†Statistik\nInfolge dessen waren dann viele Mathematiker:innen daran interessiert bei welchen Spielen mit welche Strategien mit welcher Wahrscheinlichkeit welcher Erfolg eintritt. Also zum Beispiel beim Roulette: Ich starte mit 10.000‚Ç¨ und setze immer 100‚Ç¨ + die Gewinne aus den Vorrunden auf Rot. Wie wahrscheinlich ist es, dass ich in 100 Runden 20.000‚Ç¨ habe? Wie wahrscheinlich ist es, dass ich nach 100 Runden pleite bin? Die Berechnung der Wahrscheinlichkeit solcher real einretender Szenarien (= Daten) kann man anstellen, weil man die Wahrscheinlichekit der Elementarereignisse (Rot, Schwarz, Gr√ºn) kennt. Das ist das kerninteresse der Stochastik.\nDie Statistik hingegen interessiert sich f√ºr die umgekehrte Frage: Wenn ich die Beobachtungen (Daten) habe, was kann ich dann √ºber die Wahrscheinlichkeiten der Elementarereignisse sagen?",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#bayesianischer-wahrscheinlichkeitsbegriff",
    "href": "grundlegende_begriffe.html#bayesianischer-wahrscheinlichkeitsbegriff",
    "title": "1¬† Grundlegende Begriffe",
    "section": "1.3 Bayesianischer Wahrscheinlichkeitsbegriff",
    "text": "1.3 Bayesianischer Wahrscheinlichkeitsbegriff\nWenn es sich bei den Elementarereignissen nicht um Gl√ºcksspiele handelt, kann die relative H√§ufigkeit etwas kontraintuitiv sein: Wenn die Wahrscheinlichkeit einer Befragung ergibt, dass Donald J. Trump üçä mit 54% Wahrscheinlichkeit eine neue Amtszeit bekommt, dann ist die Interpretation, dass er in 54 von 100 F√§llen gewinnt nicht besonders hilfreich. Vielmehr ist die Wahrscheinlichkeit dann eine Aussage √ºber die Unsicherheit, die wir haben, wenn wir aufgrund der Daten Schlussfolgerungen √ºber den die Daten generierenden Mechanismus treffen wollen. Die 54% w√ºrden dann also als ¬ªziemlich genau in der Mitte von unm√∂glich und sicher¬´ interpretiert werden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#bayes-theorem",
    "href": "grundlegende_begriffe.html#bayes-theorem",
    "title": "1¬† Grundlegende Begriffe",
    "section": "1.4 Bayes Theorem",
    "text": "1.4 Bayes Theorem\nBayes Theorem ist ein stochastischer Satz der eine bedingte Wahrscheinlichkeit \\(P(A|B)\\) zur bedingten Wahrscheinlichkeit \\(P(B|A)\\) in die andere Richtung umrechnet.\n\\(P(A|B)\\) ist dabei schulmathematisch als ¬ªDie Wahrscheinlichkeit dass A eintritt unter der Annahme, dass B bereits eingetreten ist¬´ zu verstehen.\n\nBeispiel: Es liegen in einer Urne 2 blaue und vier gr√ºne Kugeln, ich ziehe zwei Kugeln ohne zur√ºcklegen.\nIst das Ereignis \\(A\\) = ¬ªBlaue Kugel im ersten Zug¬´, \\(B\\) = ¬ªgr√ºne Kugel im ersten Zug¬´ und \\(C\\) = ¬ªgr√ºne Kugel im zweiten Zug¬´ dann ist \\(P(C|A) = 4/5\\) und \\(P(C|B) = 3/5\\)\n\n\n1.4.1 Dynamische Veranschaulichung\nDie beste dynamische Visualisierung zur Erkl√§rung des Bayes Theorems, die ich kenne, ist die folgende:\n\nGefragt wird ja zu Beginn nach \\(P(\\text{librarian}|\\text{meek\\;and\\;tidy\\;soul})\\) welche unter Verwendung der Wahrscheinlichkeit \\(P(\\text{meek\\;and\\;tidy\\;soul}|\\text{librarian})\\) berechnet wird.\nVerallgemeinert kann man sagen dass Bayes Theorem die Wahrscheinlichkeit \\(P(\\text{Hypothesis}|\\text{Data})\\) unter Verwendung der Wahrscheinlichkeit \\(P(\\text{Data}|\\text{Hypothesis})\\) mit folgender Formel berechnet:\n\\[\n\\overbracket[0.25pt]{P (\\text{Hypothesis} \\mid \\text{Data})}^{\\text{Posterior}} = \\frac\n{{\\overbracket[0.25pt]{P (\\text{Hypothesis})}^{\\text{Prior}}} \\times\n{\\overbracket[0.25pt]{P (\\text{Data} \\mid \\text{Hypothesis})}^{\\text{Likelihood}}}}\n{{\\underbracket[0.25pt]{{P(\\text{Data})}}_{\\text{Average likelihood}}}}\n\\]\nIm YouTube-Beispiel haben wir gesehen wie Bayes Theorem auf ein Modell angewendet wird, das wir uns als Urne mit Kugeln zweier Farben vorstellen k√∂nnen, wobei eine Farbe Farmer und eien Farbe Librarians enkodiert.\nIn der Regressionsmodellierung wird Bayes Theorem benutzt um die Parameter eines Regressionsmodells zu spezifizieren. Nehmen wir an wir wollen modellieren mit welcher Vorbereitungszeit welcher Erfolg in einer Klausur einhergeht, k√∂nnten Prior (Predictions), Data & Likelihood sowie Posterior (Predictions) wie folgt aussehen:\n Bevor wir uns aber anschauen wie wir zu diesen Posterior-Verteilungen kommen, schauen wir uns nochmal die grundlegende Unterscheidung Inferenz- und Deskriptivstatistik sowie zwischen Sch√§tzung und Testung an.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "",
    "text": "2.1 Inferenz- und Deskriptivstatistik",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#inferenz--und-deskriptivstatistik",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#inferenz--und-deskriptivstatistik",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "",
    "text": "Deskriptivstatistiken machen Aussagen √ºber vorliegende Datens√§tze z.B. ¬ªMedian aller Noten eines Zeugnisses¬´\n\n\n\nInferenzstatistiken machen anhand von Daten Aussagen √ºber (hypothetische) Mechanismen, die diese Daten erzeugen (Eid, Gollwitzer, & Schmitt, 2013) z.B. ¬ªBef√ºrworten von 100 zuf√§llig ausgew√§hlten Erwachsenen 63 Ziffernnoten in der Grundschule, wie sicher liegt dann eine Zustimmung (&gt; 50%) in der Gesamterwachsenenbev√∂lkerung vor?¬´",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#sch√§tzung-vs.-testung",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#sch√§tzung-vs.-testung",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "2.2 Sch√§tzung vs.¬†Testung",
    "text": "2.2 Sch√§tzung vs.¬†Testung\n\n\n\n\n\n\n\n\n\nFrequentistischeStatistik\nBayesianischeStatistik\n\n\n\n\nParametersch√§tzung\nKonfidenzintervalle\nPosterior Distributions\n\n\nHypothesentest\np-Werte\nBayes Faktoren/ROPE +HDI.\n\n\n\n\nInferenzstatistische Sch√§tzung (estimation with quantified uncertainty) trifft anhand von Stichproben Aussagen √ºber Parameter der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.  (Inferenzstatistische) Hypothesentests bewerten anhand von Stichprobendaten die G√ºltigkeit von Hypothesen in der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde (Kruschke & Liddell, 2018).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#hypothesenarten",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#hypothesenarten",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "2.3 Hypothesenarten",
    "text": "2.3 Hypothesenarten\nBayesianische wie frequentistischen Hypothesentests k√∂nnen unterschiedliche Arten von Hypothesen zugrunde gelegt werden:\n\nPunkthypothesen setzen Parameter gleich einer reellen Zahl; etwa \\(H_0\\text{: } \\delta = 0\\)\n√Ñquivalenzhypothesen nehmen Parameter in einem reellen Intervall an; etwa \\(H_0\\text{: } \\delta \\not\\in\\ [-.3, .3]\\)\nInformative Hypothesen nehmen eine Ordnungsrelation mehrerer Parameter an; etwa \\(\\mu_{\\text{Baseline}} &lt; \\mu_{\\text{Imaginary Pill}} &lt; \\mu_{\\text{Blinded Placebo}}\\) (Buergler u.¬†a., 2023)\n\n\nDie Art der (falsifizierten) Hypothese entscheidet wesentlich st√§rker √ºber den Informationsgehalt eines Hypothesentests als die Entscheidung f√ºr das frequentistische oder bayesianische Paradigma (Hoijtink, 2012).\n\nDies ist am leichtest anhand der Nullhypothese nachvollziehbar. Wird etwa die Nullhypothese \\(H_0\\text{: } \\delta = 0\\) verworfen, wird entsprechend die Alternativhypothese \\(H_A\\text{: } \\delta \\neq 0\\) angenommen. Diese enth√§lt aber quasi keine Information, da sie nur mit einer einzigen Beobachtung (d = 0.000000 ‚Ä¶) verworfen werden kann und im kritischen Rationalismus gilt, dass eine Aussage umso mehr Information enth√§lt, umso leichter sie verworfen werden kann (D√∂ring & Bortz, 2016).\n√Ñquivalenzhypothesen k√∂nnen sowohl frequentistisch (z.B. TOAST-Prozedur in  und JASP, Lakens, 2017) wie bayesianisch (z.B. ROPE-Ansatz Kruschke, 2015) getestet werden. F√ºr das Testen informativer Hypothesen liegen bayesianische Methoden in (u.a.) JASP und  vor (z.B. {bain}, Gu, Hoijtink, Mulder, & Rosseel, 2019).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-f√ºr-punkthypothesen",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-f√ºr-punkthypothesen",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "2.4 Bayes Faktoren f√ºr Punkthypothesen",
    "text": "2.4 Bayes Faktoren f√ºr Punkthypothesen\n\n2.4.1 Definition und deren Plausibilisierung\nDer Bayes Faktor ist wie folgt definiert:\n\\[\nBF=\\frac{P\\left(D \\mid H_1\\right)}{P\\left(D\\mid H_2\\right)}\n\\] Wobei \\(D\\) f√ºr ¬ªData¬´ steht und \\(H_1\\) und \\(H_2\\) f√ºr Modell 1 und Modell 2 stehen - oftmals wird stattdessen auch Hypothese 1 \\(H_1\\) und Hypothese 2 \\(H_2\\) geschrieben, was dasselbe meint.\nDass der BF relative Evidenz quantifiziert, wird bereits aus der Definition klar, verbreitete Fehlverst√§ndnisse (Tendeiro, Kiers, Hoekstra, Wong, & Morey, 2024) werden hoffentlich einged√§mmt, wenn man sich klar macht, dass aus dieser Definition mithilfe des Bayes Theorem folgt\n\\[\nBF=\\frac{P\\left(D \\mid H_1\\right)}{P\\left(D\\mid H_2\\right)}\\overset{\\text{Bayes Theorem}}{=}\\frac{\\frac{P\\left(D \\mid H_1\\right) \\cdot P(D)}{P\\left(H_1\\right)}}{\\frac{P\\left(D \\mid H_2\\right) \\cdot P(D)}{P\\left(H_2\\right)}}\\overset{\\text{K√ºrze } P(D)}{=}\\frac{P\\left(H_1 \\mid D\\right) \\cdot P\\left(H_2\\right)}{P\\left(H_2 \\mid D\\right) \\cdot P\\left(H_1\\right)} = \\frac{P\\left(H_1 \\mid D\\right)}{P\\left(H_2 \\mid D\\right)} \\cdot \\frac{P\\left(H_2\\right)}{P\\left(H_1\\right)}\n\\]\nStellt man nun die Gleichung um erh√§lt man:\n\\[\n\\frac{P\\left(H_1 \\mid D\\right)}{P\\left(H_2 \\mid D\\right)} = \\frac{P\\left(H_1\\right)}{P\\left(H_2\\right)} \\cdot \\frac{P\\left(D \\mid H_1\\right)}{P\\left(D\\mid H_2\\right)}\n\\]\nalso\n\\[\n\\text{Posterior Odds} = \\text{Prior Odds} \\cdot \\text{Bayes Faktor}\n\\]\nDer Bayes Faktor ist also der Multiplikator (Faktor), der die Prior Odds in die Posterior Odds transformiert (updatet).\n\n\n2.4.2 Berechnung & Interpretation im Minimalbeispiel\n\nAufgabe L√∂sungshilfe Meine Rechnung\n\n\nAngenommen zwei Bildungspolitiker:innen streiten sich √ºber die Verbreitung der Elternmeinung zur Bef√ºrwortung von G8 vs.¬†G9. Die eine Politikerin behauptet, dass 45% der Eltern G9 bef√ºrworten, die andere Politikerin behauptet, dass 58% der Eltern G9 bef√ºrworten. In einer ¬ªStudie¬´ wurden 4 Proband:innen befragt und genau drei davon waren pro G9 waren. Wie gro√ü ist der Bayes Faktor?\n\n\n\n\n\n\nIm ¬ªB√§umchen¬´ gilt laut Achtklassmathematik: Wahrscheinlichkeiten entlang eines Pfades multiplizieren, Wahrscheinlichkeiten entlang verschiedener Pfade addieren.\n\n\\(\\frac{P(\\text{drei aus 4 pro G9}|\\theta = .45) = 4\\cdot(.45 \\cdot .45 \\cdot .45 \\cdot .55)}{P(\\text{drei aus 4 pro G9}|\\theta = .58) = 4\\cdot(.58 \\cdot .58 \\cdot .58 \\cdot .42)} \\approx `{r} round((4*.45^3*.55)/(4*.58^3*.42), 3)`\\)\n\n\n\n\n\n2.4.3 Interaktive Visualisierung\nIm Beispiel zuvor, lagen Punkthypothesen vor. F√ºr diese ist die Berechnung des Bayes Faktors besonders einfach, da die Wahrscheinlichkeiten der Daten unter den Hypothesen direkt berechnet werden k√∂nnen.\n\n\n2.4.4 Interaktive Visualisierung\nIn dieser interaktiven Visualisierung kann man beobachten wie sich der Bayes Faktor in Abh√§ngigkeit von den Daten und den Hypothesen verh√§lt.\n\n\n\n\n\n\nAufgabe \n\n\n\n\n\nMacht euch mit der Bedienung der App vertraut und macht dann Vorhersagen √ºber die Ver√§nderung des Bayesfaktors, wenn sich die Daten oder Hypothesen √§ndern.\n\n\n\n#| standalone: true\n#| viewerHeight: 800\n\nlibrary(bslib)\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(shinyjs)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n   \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Punkthypothesen\"),\n         card_body(\n           sliderInput(\n               \"theta1\", \"Hypothese 1: Anteil Pro G9\",\n               min = 0,\n               max = 1,\n               value = .4,\n               step = .1\n           ),\n           sliderInput(\n               \"theta2\", \"Hypothese 2: Anteil Pro G8\",\n               min = 0,\n               max = 1,\n               value = .6,\n               step = .1\n           ))),\n    card(card_header(class = \"bg-dark\", \"Daten\"),\n         card_body(\n            numericInput(\n              \"prog9\",\n              \"n‚ÇÅ = Bef√ºrwortung G9\",\n              min = 0,\n              value = 10,\n              step = 1),\n           numericInput(\n             \"prog8\",\n             \"n‚ÇÇ = Bef√ºrwortung G8\",\n             min = 0,\n             value = 5,\n             step = 1)\n         ))), \n  card(card_header(\"Likelihoods und Bayes Factor\", class = \"bg-dark\"),\n       card_body(shinycssloaders::withSpinner(plotOutput(\"plot\"), color = \"#1bbc9d\")\n))\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n    \n# n &lt;- 30 # N()\n# obs &lt;- 20 input$prog9\n# theta1 &lt;- .5 # input$theta1\n# theta2 &lt;- .7 # input$theta2\n# wkeit1 &lt;- choose(n, obs)*theta1^obs*(1-theta1)^(n-obs) # wkeit1()\n# wkeit2 &lt;- choose(n, obs)*theta2^obs*(1-theta2)^(n-obs) # wkeit2()\n\n### custom reactive values #####################################################\nN &lt;- reactive({input$prog8 + input$prog9})\n\nwkeit1 &lt;- \n    reactive({choose(N(), \n                     input$prog9)*input$theta1^input$prog9*\n                  (1-input$theta1)^(N()-input$prog9)})\n\nwkeit2 &lt;- \n    reactive({choose(N(), \n                     input$prog9)*input$theta2^input$prog9*\n                  (1-input$theta2)^(N()-input$prog9)})\n\n### create data ################################################################\ndata &lt;- reactive({\n    return(\n        rbind(tibble(k = 1:N(),\n                     p = choose(N(), k)*input$theta1^k*(1-input$theta1)^(N()-k), \n                     theta = as.character(input$theta1)),\n              tibble(k = 1:N(),\n                     p = choose(N(), k)*input$theta2^k*(1-input$theta2)^(N()-k),  \n                     theta = as.character(input$theta2))) %&gt;% \n              mutate(obs_eq_k = k == N()) %&gt;% \n              as_tibble()\n    )\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n\n ggplot() +\n    # add whole binomial distributions with alpha\n    geom_segment(data = data() %&gt;% \n                          filter(theta == input$theta1), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p), \n                 color = \"#bc991b60\") +\n    geom_segment(data = data() %&gt;% \n                     filter(theta == input$theta2), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p), \n                 color = \"#bc1b9a50\") +\n    # add selected binomial distributions without alpha\n    geom_segment(data = data() %&gt;% \n                     filter(theta == input$theta1 & k == input$prog9), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p, color = \"#bc991b\")) +\n    geom_segment(data = data() %&gt;% \n                     filter(theta == input$theta2 & k == input$prog9), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p, color = \"#bc1b9a\")) +\n    theme_minimal() +\n    geom_text(data = tibble(x = input$prog9, y = -.005, \n                            text = paste(\"BF =\", \n                                         formatC(wkeit1()/wkeit2(), \n                                                 format = \"e\", \n                                                 digits = 2))),\n              aes(x, y, label = text)) +\n    xlab(\"Anzahl\") + ylab(\"Wahrscheinlichkeit\") +\n    ggtitle(\"Berechnung des Bayes-Faktors\", \"bei Punkthypothesen\") +\n    scale_color_identity(name = \"Likelihood\",\n                         breaks = c(\"#bc991b\", \"#bc1b9a\"),\n                         labels = c(\"Hyp. 1\", \"Hyp 2.\"),\n                         guide = \"legend\")\n})\n\n### debug ######################################################################\noutput$debug &lt;- renderPrint({\n data()\n})\n\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-f√ºr-verteilungshypothesen",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-f√ºr-verteilungshypothesen",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "2.5 Bayes Faktoren f√ºr Verteilungshypothesen",
    "text": "2.5 Bayes Faktoren f√ºr Verteilungshypothesen\nPunkthypothesen sind in den meisten sozialwissenschaftlichen Anwendungen sehr wenig informativ. In der Regel sind die Hypothesen Verteilungshypothesen. Im G8- vs.¬†G9-Beispiel w√§re eine Verteilungshypothese etwa ¬ªBef√ºrwortung von G9 in der Bev√∂lkerung liegt recht sicher zwischen 35% und 45%¬´ oder ¬ªJeder Prozentsatz der G9-Bef√ºrwortung ist gleich wahrscheinlich¬´.\nSo informativ solche Hypothesen sind, erschweren sie die Berechnung des Bayes Faktors: Im Beispiel oben hatten wir das genaue \\(\\theta\\) und konnten anhand dessen mithilfe des B√§umchen die Wahrscheinlichkeiten der Daten unter den Hypothesen berechnen. Bei Verteilungshypothesen ist das nicht mehr m√∂glich, da diese Hypothesen unendlich viele \\(\\theta\\)s enthalten. Es wird daher √ºber die \\(\\theta\\)s marginalisiert:\n\\[P\\left(D \\mid H\\right)=\\int P(D \\mid \\theta) \\cdot \\pi(\\theta) d \\theta\\] Dies kann man sich vorstellen als eine Berechnung der Likelihood \\(P\\left(D \\mid \\theta\\right)\\) f√ºr jedes \\(\\theta\\) woraus dann ein um \\(\\pi(\\theta)\\) gewichteter Durchschnitt gebildet wird.\n\n2.5.1 Interaktive Visualisierung\n\n\n\n\n\n\nAufgabe \n\n\n\n\n\nMacht euch mit der Bedienung der App vertraut. Wie √§ndern sich die Marginal Likelihoods wenn die Hypothesen weniger pr√§zise werden? Wie √§ndert sich dadurch der Bayes Faktor? Ist das im EInklang mit der Idee von Occam‚Äôs Razor?\n\n\n\n#| standalone: true\n#| viewerHeight: 850\n\nlibrary(bslib)\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(shinyjs)\nlibrary(bayesplay)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n   \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Hypothese 1\"),\n      layout_column_wrap(\n         card(\n           sliderInput(\n             \"prior_mu1\",\n             \"Mittelwert Hypothese 1\",\n             min = 0,\n             max = 1,\n             value = .42,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi1\",\n             \"Pr√§zision Hypothese 1\",\n             min = 2,\n             max = 100,\n             value = 13,\n             step = 1\n           )),\n         card(\n           plotOutput(\"prior1\", height = \"200px\")\n         )\n         )),\n   \n    card(card_header(class = \"bg-dark\", \"Hypothese 2\"),\n      layout_column_wrap(\n         card(\n          sliderInput(\n             \"prior_mu2\",\n             \"Mittelwert Hypothese 2\",\n             min = 0,\n             max = 1,\n             value = .65,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi2\",\n             \"Pr√§zision Hypothese 2\",\n             min = 2,\n             max = 100,\n             value = 13,\n             step = 1\n           )),\n           card(plotOutput(\"prior2\", height = \"200px\"))\n         ))), \n layout_column_wrap(\n  card(card_header(class = \"bg-dark\", \"Daten\"),\n     numericInput(\n                \"prog9\",\n                \"n‚ÇÅ = Bef√ºrwortung G9\",\n                min = 0,\n                value = 5,\n                step = 1),\n     numericInput(\n                \"prog8\",\n                \"n‚ÇÇ = Bef√ºrwortung G8\",\n                min = 0,\n                value = 12,\n                step = 1)\n           ), \n  card(card_header(\"Likelihoods und Bayes Factor\", class = \"bg-dark\"),\n       card_body(shinycssloaders::withSpinner(plotOutput(\"plot\"), color = \"#1bbc9d\")\n))\n))\n\n\n\nserver &lt;- function(input, output, session) {\n\n################################################################################\n### Plot of Priors                                                           ###\n################################################################################\n\n\n### custom functions ###########################################################\n# muphi_to_shapes \nmuphi_to_shapes &lt;- function(mu, phi) {\n  shape1 &lt;- mu * phi\n  shape2 &lt;- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n### aux variables ##############################################################\n# convert prior parameterization\n\nprior_shapes1 &lt;- reactive({\n  muphi_to_shapes(input$prior_mu1, input$prior_phi1)\n})\n\nprior_shapes2 &lt;- reactive({\n  muphi_to_shapes(input$prior_mu2, input$prior_phi2)\n})\n\n### Plot Prior 1 ###############################################################\noutput$prior1 &lt;- renderPlot({\n\n  p &lt;- seq(0,1, length=1000)\n\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes1()$shape1,\n          prior_shapes1()$shape2),\n    type = 'l',\n    col = \"#bc1b9a\",\n    ylab = \"W'keitsdichte\",\n    xlab = \"Anteil G9-Bef√ºrworter:innen\",\n    frame.plot = F\n    )\n}\n)\n\n### Plot Prior 2 ###############################################################\noutput$prior2 &lt;- renderPlot({\n\n  p &lt;- seq(0,1, length=1000)\n\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes2()$shape1,\n          prior_shapes2()$shape2),\n    type = 'l',\n    col = \"#bc991b\",\n    ylab = \"W'keitsdichte\",\n    xlab = \"Anteil G9-Bef√ºrworter:innen\",\n    frame.plot = F\n    )\n}\n)\n\n\n################################################################################\n### Plot of Likelihoods                                                      ###\n################################################################################\n\n### custom reactive values #####################################################\nN &lt;- reactive({input$prog8 + input$prog9})\n\n\n### compute the bf from marginal likelihoods ##################################\nwkeit1 &lt;- reactive({\n  integral(likelihood(family = \"binomial\", \n                      successes = input$prog9, \n                      trials = input$prog9 + input$prog8)*\n              prior(family = \"beta\", \n                  alpha = prior_shapes1()$shape1, \n                  beta = prior_shapes1()$shape2))\n})\n\nwkeit2 &lt;- reactive({ \n  integral(likelihood(family = \"binomial\", \n                      successes = input$prog9, \n                      trials = input$prog9 + input$prog8)*\n              prior(family = \"beta\", \n                  alpha = prior_shapes2()$shape1, \n                  beta = prior_shapes2()$shape2))\n})\n\n### create data for the two marginal likelihood distributions ####################\ndata &lt;- reactive({\n\ndata_h1 &lt;- tibble(k = 1:N(),\n                  hyp = \"Hypothese 1\")\nfor(i in 1:N()){\ndata_h1$p[i] &lt;- integral(likelihood(family = \"binomial\", \n                         successes = data_h1$k[i], \n                         trials = input$prog9 + input$prog8)*\n                   prior(family = \"beta\", \n                         alpha = prior_shapes1()$shape1, \n                         beta = prior_shapes1()$shape2))\n}\n\ndata_h1 &lt;- data_h1 %&gt;% \n  mutate(obs_eq_k = k == N()) \n\n\ndata_h2 &lt;- tibble(k = 1:N(),\n                  hyp = \"Hypothese 2\")\nfor(i in 1:N()){\ndata_h2$p[i] &lt;- integral(likelihood(family = \"binomial\", \n                         successes = data_h2$k[i], \n                         trials = input$prog9 + input$prog8)*\n                   prior(family = \"beta\", \n                         alpha = prior_shapes2()$shape1, \n                         beta = prior_shapes2()$shape2))\n}\n\ndata_h2 &lt;- data_h2 %&gt;% \n  mutate(obs_eq_k = k == N()) \n\n\n\nreturn(full_join(data_h1, data_h2))\n\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n\n ggplot() +\n    # add whole binomial distributions with alpha\n    geom_segment(data = data() %&gt;% \n                          filter(hyp == \"Hypothese 1\"), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p), \n                 color = \"#bc1b9a50\") +\n    geom_segment(data = data() %&gt;% \n                     filter(hyp == \"Hypothese 2\"), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p), \n                 color = \"#bc991b60\") +\n    # add selected binomial distributions without alpha\n    geom_segment(data = data() %&gt;% \n                     filter(hyp == \"Hypothese 1\" & k == input$prog9), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p, color = \"#bc1b9a\")) +\n    geom_segment(data = data() %&gt;% \n                     filter(hyp == \"Hypothese 2\" & k == input$prog9), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p, color = \"#bc991b\")) +\n    theme_minimal() +\n    geom_text(data = tibble(x = input$prog9, y = -.005, \n                            text = paste(\"BF =\", \n                                         formatC(wkeit1()/wkeit2(), \n                                                 format = \"e\", \n                                                 digits = 2))),\n              aes(x, y, label = text)) +\n    xlab(\"Anzahl\") + ylab(\"Wahrscheinlichkeit\") +\n    ggtitle(\"Berechnung des Bayes-Faktors\", \"bei Punkthypothesen\") +\n    scale_color_identity(name = \"Marginal Likelihood\",\n                         breaks = c(\"#bc1b9a\", \"#bc991b\"),\n                         labels = c(\"Hyp. 1\", \"Hyp 2.\"),\n                         guide = \"legend\") +\n    theme(legend.position = \"bottom\")\n})\n\n### debug ######################################################################\noutput$debug &lt;- renderPrint({\n data()\n})\n\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\nBuergler, S., Sezer, D., Bagge, N., Kirsch, I., Locher, C., Carvalho, C., & Gaab, J. (2023). Imaginary Pills and Open-Label Placebos Can Reduce Test Anxiety by Means of Placebo Mechanisms  Scientific Reports. Scientific Reports, 13(1), 2624.\n\n\nD√∂ring, N., & Bortz, J. (2016). Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften (5., vollst). Berlin, Heidelberg: Springer.\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik Und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\n\n\nGu, X., Hoijtink, H., Mulder, J., & Rosseel, Y. (2019). Bain: A Program for Bayesian Testing of Order Constrained Hypotheses in Structural Equation Models. Journal of Statistical Computation and Simulation, 89(8), 1526‚Äì1553.\n\n\nHoijtink, H. (2012). Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists. Boca Raton: CRC.\n\n\nKruschke, J. K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd Aufl.). Academic Press.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis Testing, Estimation, Meta-Analysis, and Power Analysis from a Bayesian Perspective. Psychonomic Bulletin & Review, 25, 178‚Äì206.\n\n\nLakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses. Social Psychological and Personality Science, 8(4), 355‚Äì362.\n\n\nTendeiro, J. N., Kiers, H. A. L., Hoekstra, R., Wong, T. K., & Morey, R. D. (2024). Diagnosing the Misuse of the Bayes Factor in Applied Research. Advances in Methods and Practices in Psychological Science, 7(1), 25152459231213371.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "fully_bayesian_estimation.html",
    "href": "fully_bayesian_estimation.html",
    "title": "3¬† The (Fully) Bayesian Estimation Approach",
    "section": "",
    "text": "3.1 Interaktive Visualisierung\nDer folgenden interaktiven Visualisierung ist als Prior eine Betaverteilung und als Likelihood eine Binomialverteilung vorgegeben. Wendet man Bayes Theorem auf die entsprechenden Funktionsvorschriften an kann man zeigen, dass als Posterior wieder eine Betaverteilung entsteht. Diesen seltenen Fall der analytischen (¬ªgeschlossenen¬´) L√∂sbarkeit nennt man conjugacy prior (Lambert, 2018).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>The (Fully) Bayesian Estimation Approach</span>"
    ]
  },
  {
    "objectID": "fully_bayesian_estimation.html#interaktive-visualisierung",
    "href": "fully_bayesian_estimation.html#interaktive-visualisierung",
    "title": "3¬† The (Fully) Bayesian Estimation Approach",
    "section": "",
    "text": "Aufgabe L√∂sungsvorschlag \n\n\nProbiert aus, was in der folgenden interaktiven Visualisierung mit dem Posterior passiert,\n\nwenn ein flacher Prior gew√§hlt ist, der Anteil der G9-Bef√ºrworter:innen gleich bleibt, aber die Anzahl der Beobachtungen steigen (also z.B. n‚ÇÅ = 2 & n‚ÇÇ = 4; n‚ÇÅ = 5 & n‚ÇÇ = 10; n‚ÇÅ = 23 & n‚ÇÇ = 46; ‚Ä¶)\nwenn ein pr√§ziser Prior gew√§hlt ist, und die Anzahl der Beobachtungen klein ist\nwenn ein pr√§ziser Prior gew√§hlt ist, dessen Mittelwert ¬ªweit¬´ vom Anteil der G9-Bef√ºrworter:innen entfernt ist und die Anzahl der Beobachtungen steigen\n\n\n\n\nDer Posterior ist vollst√§ndig durch die Daten getrieben. Der Modus des Posteriors ist gleich dem Anteil der G9-Bef√ºrworter:innen. Mit steigender Anzahl der Beobachtungen wird der Posterior schmaler, das HDI kleiner.\nDer Posterior ist recht stark durch den Prior gepr√§gt.\nMit steigender Anzahl der Beobachtungen sinkt der Einfluss des Priors.\n\n\n\n\n#| standalone: true\n#| viewerHeight: 800\n\nlibrary(bslib)\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Prior\"),\n         card_body(\n           sliderInput(\n             \"prior_mu\",\n             \"Prior Mean\",\n             min = 0,\n             max = 1,\n             value = .5,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi\",\n             \"Prior Precision\",\n             min = 2,\n             max = 100,\n             value = 3,\n             step = 1\n           )\n         )),\n    card(card_header(class = \"bg-dark\", \"Data\"),\n         card_body(\n           numericInput(\n             \"successes\",\n             \"n‚ÇÅ = Zustimmung G9\",\n             min = 0,\n             value = 13,\n             step = 1\n           ),\n           numericInput(\n             \"failures\",\n             \"n‚ÇÇ = Ablehnung G9\",\n             min = 0,\n             value = 8,\n             step = 1\n           )\n         ))), \n  card(card_header(\"Posterior\", class = \"bg-dark\"),\n       card_body(plotOutput(\"plot\")))\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n### custom functions ###########################################################\n# muphi_to_shapes \nmuphi_to_shapes &lt;- function(mu, phi) {\n  shape1 &lt;- mu * phi\n  shape2 &lt;- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n### aux variables ##############################################################\n# convert prior parameterization\n\nprior_shapes &lt;- reactive({\n  muphi_to_shapes(input$prior_mu, input$prior_phi)\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n  \n  # set x-axis\n  p &lt;- seq(0,1, length=1000)\n  \n  # compute max-desity for ylim and legend position\n  density_max &lt;-\n    max(c(\n      dbeta(p,\n            prior_shapes()$shape1,\n            prior_shapes()$shape2),\n      dbeta(\n        p,\n        prior_shapes()$shape1 + input$successes,\n        prior_shapes()$shape2 + input$failures\n      )\n    ))\n  \n  # compute lower bound of 96%-HPDI\n  hpdi_lb &lt;-\n    qbeta(.02,\n           prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  # compute upper bound of 96%-HPDI\n  hpdi_ub &lt;-\n    qbeta(.98,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  \n  # create plot\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes()$shape1,\n          prior_shapes()$shape2),\n    type = 'l',\n    col = \"#1bbc9d\",\n    ylab = \"Wahrscheinlichkeitsdichte\",\n    xlab = \"Anteil G9-Bef√ºrworter:innen\",\n    frame.plot = F,\n    ylim = c(0, density_max)\n    )\n  lines(p,\n        dbeta(\n          p,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures\n          ),\n          col = '#EA80FC'\n        )\n  polygon(c(hpdi_lb, hpdi_lb, hpdi_ub, hpdi_ub),\n          c(0, density_max/40, density_max/40, 0),\n          col = \"#EA80FC30\",\n          border = \"#EA80FC00\")\n  legend(\n    bty = \"n\",\n    .8,\n    density_max,\n    c('Prior', 'Posterior', '96% HDI'),\n    lty = c(1, 1, 1),\n    lwd = c(1, 1, 8),\n    col = c('#1bbc9d', '#EA80FC', '#EA80FC30')\n  )\n\n})\n\n### debug ######################################################################\n# output$debug &lt;- renderPrint({\n#   max(c(\n#                dbeta(p, \n#                      prior_shapes()$shape1, \n#                      prior_shapes()$shape2),\n#                dbeta(p, \n#                      prior_shapes()$shape1 + input$successes, \n#                      prior_shapes()$shape2 + input$failures))\n#              )\n#              \n# })\n\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\nLambert, B. (2018). A Student‚Äôs Guide to Bayesian Statistics. Los Angeles: SAGE.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>The (Fully) Bayesian Estimation Approach</span>"
    ]
  },
  {
    "objectID": "bayesian_gaussian_regression.html",
    "href": "bayesian_gaussian_regression.html",
    "title": "4¬† Bayesian (Gaussian) Regression",
    "section": "",
    "text": "4.1 Worked out Example",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Bayesian (Gaussian) Regression</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Buergler, S., Sezer, D., Bagge, N., Kirsch, I., Locher, C., Carvalho,\nC., & Gaab, J. (2023). Imaginary pills and\nopen-label placebos can reduce test anxiety by means of placebo\nmechanisms  Scientific Reports.\nScientific Reports, 13(1), 2624.\n\n\nD√∂ring, N., & Bortz, J. (2016). Forschungsmethoden und\nEvaluation in den Sozial- und Humanwissenschaften (5.,\nvollst). Berlin, Heidelberg: Springer.\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und\nForschungsmethoden: Lehrbuch. Mit\nOnline-Materialien (3rd ed.). Beltz.\n\n\nGu, X., Hoijtink, H., Mulder, J., & Rosseel, Y. (2019). Bain:\nA program for Bayesian testing of order\nconstrained hypotheses in structural equation models. Journal of\nStatistical Computation and Simulation, 89(8), 1526‚Äì1553.\n\n\nHoijtink, H. (2012). Informative hypotheses: Theory and\npractice for behavioral and social scientists. Boca\nRaton: CRC.\n\n\nKruschke, J. K. (2015). Doing Bayesian data analysis:\nA tutorial with R, JAGS, and\nStan (2nd ed.). Academic Press.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). The\nBayesian new statistics: Hypothesis testing,\nestimation, meta-analysis, and power analysis from a\nBayesian perspective. Psychonomic Bulletin &\nReview, 25, 178‚Äì206.\n\n\nLakens, D. (2017). Equivalence\nTests: A Practical Primer for t\nTests, Correlations, and\nMeta-Analyses. Social Psychological and Personality\nScience, 8(4), 355‚Äì362.\n\n\nLambert, B. (2018). A student‚Äôs guide to Bayesian\nstatistics. Los Angeles: SAGE.\n\n\nTendeiro, J. N., Kiers, H. A. L., Hoekstra, R., Wong, T. K., &\nMorey, R. D. (2024). Diagnosing the\nMisuse of the Bayes Factor in Applied\nResearch. Advances in Methods and Practices in\nPsychological Science, 7(1), 25152459231213371.",
    "crumbs": [
      "Literatur"
    ]
  }
]