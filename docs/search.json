[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GRAPH Sommerakdemie 24",
    "section": "",
    "text": "Willkommen 👋!\nHier finden sich\n\nErklärungen,\nVideos,\nAufgaben,\nDaten und\nCode\n\nfür unseren Kurs Bayesian Regression Modelling.\nZu Beginn des Kurses bitte ich alle eine aktuelle Version von  und Studio installiert zu haben und außerdem - falls noch nicht mit {brms} gearbeitet wurde - dieser Anleitung zur Installation und Verknüpfung des -Paketes {brms} zu folgen. Bei Problemen bitte gerne bei mir vorab melden!\n\n\n\n\n\n\nZweck dieses E-Books \n\n\n\n\n\nDieses E-Book soll keine Lehrbuch zum Thema Bayesian Regression Modelling sein. Vielmehr ein Notizbuch für den Workshop mit einer Sammlung von Code, Links, Datensätzen und Literaturverweisen.",
    "crumbs": [
      "Willkommen 👋!"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html",
    "href": "grundlegende_begriffe.html",
    "title": "1  Grundlegende Begriffe",
    "section": "",
    "text": "1.1 Wahrscheinlichkeitsbegriff von Laplace\nDie mathematische Wahrscheinlichkeitstheorie (Stochastik) ist ein vergleichsweise junge Subdisziplin, die erst zu Beginn des 20. Jahrhunderts axiomatisch formalisiert wurde. in diesen Ansätzen definiert man Wahrscheinlichkeitsmaße z.B. durch die folgenden Axiome.\nDas ist weder besonders intuitiv noch hilfreich für die Anwendung in der Datenanalyse. Eine wichtige Kontextinfromation könnte jedoch sein, dass die Wahrscheinlichkeitsrechnung bis ins 19. Jhd. hinein vor allem als Hilfsmittel für Glücksspiele und Wetten entwickelt wurde. In diesem Kontext ist es recht hilfreich und intuitiv Wahrscheinlichkeit als relative Häufigkeit zu verstehen. So findet man auch etwa in Mathematikbüchern der 7.ten Klasse Aussagen wie",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#wahrscheinlichkeitsbegriff-von-laplace",
    "href": "grundlegende_begriffe.html#wahrscheinlichkeitsbegriff-von-laplace",
    "title": "1  Grundlegende Begriffe",
    "section": "",
    "text": "“Die Wahrscheinlichkeit, dass eine gerade Zahl gewürfelt wird, beträgt 3/6, denn es gibt 6 mögliche Ergebnisse und drei günstige.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#stochastik-vs.-statistik",
    "href": "grundlegende_begriffe.html#stochastik-vs.-statistik",
    "title": "1  Grundlegende Begriffe",
    "section": "1.2 Stochastik vs. Statistik",
    "text": "1.2 Stochastik vs. Statistik\nInfolge dessen waren dann viele Mathematiker:innen daran interessiert bei welchen Spielen mit welche Strategien mit welcher Wahrscheinlichkeit welcher Erfolg eintritt. Also zum Beispiel beim Roulette: Ich starte mit 10.000€ und setze immer 100€ + die Gewinne aus den Vorrunden auf Rot. Wie wahrscheinlich ist es, dass ich in 100 Runden 20.000€ habe? Wie wahrscheinlich ist es, dass ich nach 100 Runden pleite bin? Die Berechnung der Wahrscheinlichkeit solcher real einretender Szenarien (= Daten) kann man anstellen, weil man die Wahrscheinlichekit der Elementarereignisse (Rot, Schwarz, Grün) kennt. Das ist das kerninteresse der Stochastik.\nDie Statistik hingegen interessiert sich für die umgekehrte Frage: Wenn ich die Beobachtungen (Daten) habe, was kann ich dann über die Wahrscheinlichkeiten der Elementarereignisse sagen?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#bayesianischer-wahrscheinlichkeitsbegriff",
    "href": "grundlegende_begriffe.html#bayesianischer-wahrscheinlichkeitsbegriff",
    "title": "1  Grundlegende Begriffe",
    "section": "1.3 Bayesianischer Wahrscheinlichkeitsbegriff",
    "text": "1.3 Bayesianischer Wahrscheinlichkeitsbegriff\nWenn es sich bei den Elementarereignissen nicht um Glücksspiele handelt, kann die relative Häufigkeit etwas kontraintuitiv sein: Wenn die Wahrscheinlichkeit einer Befragung ergibt, dass Donald J. Trump 🍊 mit 54% Wahrscheinlichkeit eine neue Amtszeit bekommt, dann ist die Interpretation, dass er in 54 von 100 Fällen gewinnt nicht besonders hilfreich. Vielmehr ist die Wahrscheinlichkeit dann eine Aussage über die Unsicherheit, die wir haben, wenn wir aufgrund der Daten Schlussfolgerungen über den die Daten generierenden Mechanismus treffen wollen. Die 54% würden dann also als »ziemlich genau in der Mitte von unmöglich und sicher« interpretiert werden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#bayes-theorem",
    "href": "grundlegende_begriffe.html#bayes-theorem",
    "title": "1  Grundlegende Begriffe",
    "section": "1.4 Bayes Theorem",
    "text": "1.4 Bayes Theorem\nBayes Theorem ist ein stochastischer Satz der eine bedingte Wahrscheinlichkeit \\(P(A|B)\\) zur bedingten Wahrscheinlichkeit \\(P(B|A)\\) in die andere Richtung umrechnet.\n\\(P(A|B)\\) ist dabei schulmathematisch als »Die Wahrscheinlichkeit dass A eintritt unter der Annahme, dass B bereits eingetreten ist« zu verstehen.\n\nBeispiel: Es liegen in einer Urne 2 blaue und vier grüne Kugeln, ich ziehe zwei Kugeln ohne zurücklegen.\nIst das Ereignis \\(A\\) = »Blaue Kugel im ersten Zug«, \\(B\\) = »grüne Kugel im ersten Zug« und \\(C\\) = »grüne Kugel im zweiten Zug« dann ist \\(P(C|A) = 4/5\\) und \\(P(C|B) = 3/5\\)\n\n\n1.4.1 Dynamische Veranschaulichung\nDie beste dynamische Visualisierung zur Erklärung des Bayes Theorems, die ich kenne, ist die folgende:\n\nGefragt wird ja zu Beginn nach \\(P(\\text{librarian}|\\text{meek\\;and\\;tidy\\;soul})\\) welche unter Verwendung der Wahrscheinlichkeit \\(P(\\text{meek\\;and\\;tidy\\;soul}|\\text{librarian})\\) berechnet wird.\nVerallgemeinert kann man sagen dass Bayes Theorem die Wahrscheinlichkeit \\(P(\\text{Hypothesis}|\\text{Data})\\) unter Verwendung der Wahrscheinlichkeit \\(P(\\text{Data}|\\text{Hypothesis})\\) mit folgender Formel berechnet:\n\\[\n\\overbracket[0.25pt]{P (\\text{Hypothesis} \\mid \\text{Data})}^{\\text{Posterior}} = \\frac\n{{\\overbracket[0.25pt]{P (\\text{Hypothesis})}^{\\text{Prior}}} \\times\n{\\overbracket[0.25pt]{P (\\text{Data} \\mid \\text{Hypothesis})}^{\\text{Likelihood}}}}\n{{\\underbracket[0.25pt]{{P(\\text{Data})}}_{\\text{Average likelihood}}}}\n\\]\nIm YouTube-Beispiel haben wir gesehen wie Bayes Theorem auf ein Modell angewendet wird, das wir uns als Urne mit Kugeln zweier Farben vorstellen können, wobei eine Farbe Farmer und eien Farbe Librarians enkodiert.\nIn der Regressionsmodellierung wird Bayes Theorem benutzt um die Parameter eines Regressionsmodells zu spezifizieren. Nehmen wir an wir wollen modellieren mit welcher Vorbereitungszeit welcher Erfolg in einer Klausur einhergeht, könnten Prior (Predictions), Data & Likelihood sowie Posterior (Predictions) wie folgt aussehen:\n Bevor wir uns aber anschauen wie wir zu diesen Posterior-Verteilungen kommen, schauen wir uns nochmal die grundlegende Unterscheidung Inferenz- und Deskriptivstatistik sowie zwischen Schätzung und Testung an.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html",
    "title": "2  Hypothesen testen vs. Parameter schätzen",
    "section": "",
    "text": "2.1 Inferenz- und Deskriptivstatistik",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesen testen vs. Parameter schätzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#inferenz--und-deskriptivstatistik",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#inferenz--und-deskriptivstatistik",
    "title": "2  Hypothesen testen vs. Parameter schätzen",
    "section": "",
    "text": "Deskriptivstatistiken machen Aussagen über vorliegende Datensätze z.B. »Median aller Noten eines Zeugnisses«\n\n\n\nInferenzstatistiken machen anhand von Daten Aussagen über (hypothetische) Mechanismen, die diese Daten erzeugen (Eid, Gollwitzer, & Schmitt, 2013) z.B. »Befürworten von 100 zufällig ausgewählten Erwachsenen 63 Ziffernnoten in der Grundschule, wie sicher liegt dann eine Zustimmung (&gt; 50%) in der Gesamterwachsenenbevölkerung vor?«",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesen testen vs. Parameter schätzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#schätzung-vs.-testung",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#schätzung-vs.-testung",
    "title": "2  Hypothesen testen vs. Parameter schätzen",
    "section": "2.2 Schätzung vs. Testung",
    "text": "2.2 Schätzung vs. Testung\n\n\n\n\n\n\n\n\n\nFrequentistischeStatistik\nBayesianischeStatistik\n\n\n\n\nParameterschätzung\nKonfidenzintervalle\nPosterior Distributions\n\n\nHypothesentest\np-Werte\nBayes Faktoren/ROPE +HDI.\n\n\n\n\nInferenzstatistische Schätzung (estimation with quantified uncertainty) trifft anhand von Stichproben Aussagen über Parameter der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.  (Inferenzstatistische) Hypothesentests bewerten anhand von Stichprobendaten die Gültigkeit von Hypothesen in der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde (Kruschke & Liddell, 2018).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesen testen vs. Parameter schätzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#hypothesenarten",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#hypothesenarten",
    "title": "2  Hypothesen testen vs. Parameter schätzen",
    "section": "2.3 Hypothesenarten",
    "text": "2.3 Hypothesenarten\nBayesianische wie frequentistischen Hypothesentests können unterschiedliche Arten von Hypothesen zugrunde gelegt werden:\n\nPunkthypothesen setzen Parameter gleich einer reellen Zahl; etwa \\(H_0\\text{: } \\delta = 0\\)\nÄquivalenzhypothesen nehmen Parameter in einem reellen Intervall an; etwa \\(H_0\\text{: } \\delta \\not\\in\\ [-.3, .3]\\)\nInformative Hypothesen nehmen eine Ordnungsrelation mehrerer Parameter an; etwa \\(\\mu_{\\text{Baseline}} &lt; \\mu_{\\text{Imaginary Pill}} &lt; \\mu_{\\text{Blinded Placebo}}\\) (Buergler u. a., 2023)\n\n\nDie Art der (falsifizierten) Hypothese entscheidet wesentlich stärker über den Informationsgehalt eines Hypothesentests als die Entscheidung für das frequentistische oder bayesianische Paradigma (Hoijtink, 2012).\n\nDies ist am leichtest anhand der Nullhypothese nachvollziehbar. Wird etwa die Nullhypothese \\(H_0\\text{: } \\delta = 0\\) verworfen, wird entsprechend die Alternativhypothese \\(H_A\\text{: } \\delta \\neq 0\\) angenommen. Diese enthält aber quasi keine Information, da sie nur mit einer einzigen Beobachtung (d = 0.000000 …) verworfen werden kann und im kritischen Rationalismus gilt, dass eine Aussage umso mehr Information enthält, umso leichter sie verworfen werden kann (Döring & Bortz, 2016).\nÄquivalenzhypothesen können sowohl frequentistisch (z.B. TOAST-Prozedur in  und JASP, Lakens, 2017) wie bayesianisch (z.B. ROPE-Ansatz Kruschke, 2015) getestet werden. Für das Testen informativer Hypothesen liegen bayesianische Methoden in (u.a.) JASP und  vor (z.B. {bain}, Gu, Hoijtink, Mulder, & Rosseel, 2019).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesen testen vs. Parameter schätzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-für-punkthypothesen",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-für-punkthypothesen",
    "title": "2  Hypothesen testen vs. Parameter schätzen",
    "section": "2.4 Bayes Faktoren für Punkthypothesen",
    "text": "2.4 Bayes Faktoren für Punkthypothesen\n\n2.4.1 Definition und deren Plausibilisierung\nDer Bayes Faktor ist wie folgt definiert:\n\\[\nBF=\\frac{P\\left(D \\mid H_1\\right)}{P\\left(D\\mid H_2\\right)}\n\\] Wobei \\(D\\) für »Data« steht und \\(H_1\\) und \\(H_2\\) für Modell 1 und Modell 2 stehen - oftmals wird stattdessen auch Hypothese 1 \\(H_1\\) und Hypothese 2 \\(H_2\\) geschrieben, was dasselbe meint.\nDass der BF relative Evidenz quantifiziert, wird bereits aus der Definition klar, verbreitete Fehlverständnisse (Tendeiro, Kiers, Hoekstra, Wong, & Morey, 2024) werden hoffentlich eingedämmt, wenn man sich klar macht, dass aus dieser Definition mithilfe des Bayes Theorem folgt\n\\[\nBF=\\frac{P\\left(D \\mid H_1\\right)}{P\\left(D\\mid H_2\\right)}\\overset{\\text{Bayes Theorem}}{=}\\frac{\\frac{P\\left(D \\mid H_1\\right) \\cdot P(D)}{P\\left(H_1\\right)}}{\\frac{P\\left(D \\mid H_2\\right) \\cdot P(D)}{P\\left(H_2\\right)}}\\overset{\\text{Kürze } P(D)}{=}\\frac{P\\left(H_1 \\mid D\\right) \\cdot P\\left(H_2\\right)}{P\\left(H_2 \\mid D\\right) \\cdot P\\left(H_1\\right)} = \\frac{P\\left(H_1 \\mid D\\right)}{P\\left(H_2 \\mid D\\right)} \\cdot \\frac{P\\left(H_2\\right)}{P\\left(H_1\\right)}\n\\]\nStellt man nun die Gleichung um erhält man:\n\\[\n\\frac{P\\left(H_1 \\mid D\\right)}{P\\left(H_2 \\mid D\\right)} = \\frac{P\\left(H_1\\right)}{P\\left(H_2\\right)} \\cdot \\frac{P\\left(D \\mid H_1\\right)}{P\\left(D\\mid H_2\\right)}\n\\]\nalso\n\\[\n\\text{Posterior Odds} = \\text{Prior Odds} \\cdot \\text{Bayes Faktor}\n\\]\nDer Bayes Faktor ist also der Multiplikator (Faktor), der die Prior Odds in die Posterior Odds transformiert (updatet).\n\n\n2.4.2 Berechnung & Interpretation im Minimalbeispiel\n\nAufgabe Lösungshilfe Meine Rechnung\n\n\nAngenommen zwei Bildungspolitiker:innen streiten sich über die Verbreitung der Elternmeinung zur Befürwortung von G8 vs. G9. Die eine Politikerin behauptet, dass 45% der Eltern G9 befürworten, die andere Politikerin behauptet, dass 58% der Eltern G9 befürworten. In einer »Studie« wurden 4 Proband:innen befragt und genau drei davon waren pro G9 waren. Wie groß ist der Bayes Faktor?\n\n\n\n\n\n\nIm »Bäumchen« gilt laut Achtklassmathematik: Wahrscheinlichkeiten entlang eines Pfades multiplizieren, Wahrscheinlichkeiten entlang verschiedener Pfade addieren.\n\n\\(\\frac{P(\\text{drei aus 4 pro G9}|\\theta = .45) = 4\\cdot(.45 \\cdot .45 \\cdot .45 \\cdot .55)}{P(\\text{drei aus 4 pro G9}|\\theta = .58) = 4\\cdot(.58 \\cdot .58 \\cdot .58 \\cdot .42)} \\approx `{r} round((4*.45^3*.55)/(4*.58^3*.42), 3)`\\)\n\n\n\n\n\n2.4.3 Interaktive Visualisierung\nIm Beispiel zuvor, lagen Punkthypothesen vor. Für diese ist die Berechnung des Bayes Faktors besonders einfach, da die Wahrscheinlichkeiten der Daten unter den Hypothesen direkt berechnet werden können.\n\n\n2.4.4 Interaktive Visualisierung\nIn dieser interaktiven Visualisierung kann man beobachten wie sich der Bayes Faktor in Abhängigkeit von den Daten und den Hypothesen verhält.\n\n\n\n\n\n\nAufgabe \n\n\n\n\n\nMacht euch mit der Bedienung der App vertraut und macht dann Vorhersagen über die Veränderung des Bayesfaktors, wenn sich die Daten oder Hypothesen ändern.\n\n\n\n#| standalone: true\n#| viewerHeight: 800\n\nlibrary(bslib)\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(shinyjs)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n   \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Punkthypothesen\"),\n         card_body(\n           sliderInput(\n               \"theta1\", \"Hypothese 1: Anteil Pro G9\",\n               min = 0,\n               max = 1,\n               value = .4,\n               step = .1\n           ),\n           sliderInput(\n               \"theta2\", \"Hypothese 2: Anteil Pro G8\",\n               min = 0,\n               max = 1,\n               value = .6,\n               step = .1\n           ))),\n    card(card_header(class = \"bg-dark\", \"Daten\"),\n         card_body(\n            numericInput(\n              \"prog9\",\n              \"n₁ = Befürwortung G9\",\n              min = 0,\n              value = 10,\n              step = 1),\n           numericInput(\n             \"prog8\",\n             \"n₂ = Befürwortung G8\",\n             min = 0,\n             value = 5,\n             step = 1)\n         ))), \n  card(card_header(\"Likelihoods und Bayes Factor\", class = \"bg-dark\"),\n       card_body(shinycssloaders::withSpinner(plotOutput(\"plot\"), color = \"#1bbc9d\")\n))\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n    \n# n &lt;- 30 # N()\n# obs &lt;- 20 input$prog9\n# theta1 &lt;- .5 # input$theta1\n# theta2 &lt;- .7 # input$theta2\n# wkeit1 &lt;- choose(n, obs)*theta1^obs*(1-theta1)^(n-obs) # wkeit1()\n# wkeit2 &lt;- choose(n, obs)*theta2^obs*(1-theta2)^(n-obs) # wkeit2()\n\n### custom reactive values #####################################################\nN &lt;- reactive({input$prog8 + input$prog9})\n\nwkeit1 &lt;- \n    reactive({choose(N(), \n                     input$prog9)*input$theta1^input$prog9*\n                  (1-input$theta1)^(N()-input$prog9)})\n\nwkeit2 &lt;- \n    reactive({choose(N(), \n                     input$prog9)*input$theta2^input$prog9*\n                  (1-input$theta2)^(N()-input$prog9)})\n\n### create data ################################################################\ndata &lt;- reactive({\n    return(\n        rbind(tibble(k = 1:N(),\n                     p = choose(N(), k)*input$theta1^k*(1-input$theta1)^(N()-k), \n                     theta = as.character(input$theta1)),\n              tibble(k = 1:N(),\n                     p = choose(N(), k)*input$theta2^k*(1-input$theta2)^(N()-k),  \n                     theta = as.character(input$theta2))) %&gt;% \n              mutate(obs_eq_k = k == N()) %&gt;% \n              as_tibble()\n    )\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n\n ggplot() +\n    # add whole binomial distributions with alpha\n    geom_segment(data = data() %&gt;% \n                          filter(theta == input$theta1), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p), \n                 color = \"#bc991b60\") +\n    geom_segment(data = data() %&gt;% \n                     filter(theta == input$theta2), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p), \n                 color = \"#bc1b9a50\") +\n    # add selected binomial distributions without alpha\n    geom_segment(data = data() %&gt;% \n                     filter(theta == input$theta1 & k == input$prog9), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p, color = \"#bc991b\")) +\n    geom_segment(data = data() %&gt;% \n                     filter(theta == input$theta2 & k == input$prog9), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p, color = \"#bc1b9a\")) +\n    theme_minimal() +\n    geom_text(data = tibble(x = input$prog9, y = -.005, \n                            text = paste(\"BF =\", \n                                         formatC(wkeit1()/wkeit2(), \n                                                 format = \"e\", \n                                                 digits = 2))),\n              aes(x, y, label = text)) +\n    xlab(\"Anzahl\") + ylab(\"Wahrscheinlichkeit\") +\n    ggtitle(\"Berechnung des Bayes-Faktors\", \"bei Punkthypothesen\") +\n    scale_color_identity(name = \"Likelihood\",\n                         breaks = c(\"#bc991b\", \"#bc1b9a\"),\n                         labels = c(\"Hyp. 1\", \"Hyp 2.\"),\n                         guide = \"legend\")\n})\n\n### debug ######################################################################\noutput$debug &lt;- renderPrint({\n data()\n})\n\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesen testen vs. Parameter schätzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-für-verteilungshypothesen",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-für-verteilungshypothesen",
    "title": "2  Hypothesen testen vs. Parameter schätzen",
    "section": "2.5 Bayes Faktoren für Verteilungshypothesen",
    "text": "2.5 Bayes Faktoren für Verteilungshypothesen\nPunkthypothesen sind in den meisten sozialwissenschaftlichen Anwendungen sehr wenig informativ. In der Regel sind die Hypothesen Verteilungshypothesen. Im G8- vs. G9-Beispiel wäre eine Verteilungshypothese etwa »Befürwortung von G9 in der Bevölkerung liegt recht sicher zwischen 35% und 45%« oder »Jeder Prozentsatz der G9-Befürwortung ist gleich wahrscheinlich«.\nSo informativ solche Hypothesen sind, erschweren sie die Berechnung des Bayes Faktors: Im Beispiel oben hatten wir das genaue \\(\\theta\\) und konnten anhand dessen mithilfe des Bäumchen die Wahrscheinlichkeiten der Daten unter den Hypothesen berechnen. Bei Verteilungshypothesen ist das nicht mehr möglich, da diese Hypothesen unendlich viele \\(\\theta\\)s enthalten. Es wird daher über die \\(\\theta\\)s marginalisiert:\n\\[P\\left(D \\mid H\\right)=\\int P(D \\mid \\theta) \\cdot \\pi(\\theta) d \\theta\\] Dies kann man sich vorstellen als eine Berechnung der Likelihood \\(P\\left(D \\mid \\theta\\right)\\) für jedes \\(\\theta\\) woraus dann ein um \\(\\pi(\\theta)\\) gewichteter Durchschnitt gebildet wird.\n\n2.5.1 Interaktive Visualisierung\n\n\n\n\n\n\nAufgabe \n\n\n\n\n\nMacht euch mit der Bedienung der App vertraut. Wie ändern sich die Marginal Likelihoods wenn die Hypothesen weniger präzise werden? Wie ändert sich dadurch der Bayes Faktor? Ist das im EInklang mit der Idee von Occam’s Razor?\n\n\n\n#| standalone: true\n#| viewerHeight: 850\n\nlibrary(bslib)\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(shinyjs)\nlibrary(bayesplay)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n   \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Hypothese 1\"),\n      layout_column_wrap(\n         card(\n           sliderInput(\n             \"prior_mu1\",\n             \"Mittelwert Hypothese 1\",\n             min = 0,\n             max = 1,\n             value = .42,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi1\",\n             \"Präzision Hypothese 1\",\n             min = 2,\n             max = 100,\n             value = 13,\n             step = 1\n           )),\n         card(\n           plotOutput(\"prior1\", height = \"200px\")\n         )\n         )),\n   \n    card(card_header(class = \"bg-dark\", \"Hypothese 2\"),\n      layout_column_wrap(\n         card(\n          sliderInput(\n             \"prior_mu2\",\n             \"Mittelwert Hypothese 2\",\n             min = 0,\n             max = 1,\n             value = .65,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi2\",\n             \"Präzision Hypothese 2\",\n             min = 2,\n             max = 100,\n             value = 13,\n             step = 1\n           )),\n           card(plotOutput(\"prior2\", height = \"200px\"))\n         ))), \n layout_column_wrap(\n  card(card_header(class = \"bg-dark\", \"Daten\"),\n     numericInput(\n                \"prog9\",\n                \"n₁ = Befürwortung G9\",\n                min = 0,\n                value = 5,\n                step = 1),\n     numericInput(\n                \"prog8\",\n                \"n₂ = Befürwortung G8\",\n                min = 0,\n                value = 12,\n                step = 1)\n           ), \n  card(card_header(\"Likelihoods und Bayes Factor\", class = \"bg-dark\"),\n       card_body(shinycssloaders::withSpinner(plotOutput(\"plot\"), color = \"#1bbc9d\")\n))\n))\n\n\n\nserver &lt;- function(input, output, session) {\n\n################################################################################\n### Plot of Priors                                                           ###\n################################################################################\n\n\n### custom functions ###########################################################\n# muphi_to_shapes \nmuphi_to_shapes &lt;- function(mu, phi) {\n  shape1 &lt;- mu * phi\n  shape2 &lt;- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n### aux variables ##############################################################\n# convert prior parameterization\n\nprior_shapes1 &lt;- reactive({\n  muphi_to_shapes(input$prior_mu1, input$prior_phi1)\n})\n\nprior_shapes2 &lt;- reactive({\n  muphi_to_shapes(input$prior_mu2, input$prior_phi2)\n})\n\n### Plot Prior 1 ###############################################################\noutput$prior1 &lt;- renderPlot({\n\n  p &lt;- seq(0,1, length=1000)\n\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes1()$shape1,\n          prior_shapes1()$shape2),\n    type = 'l',\n    col = \"#bc1b9a\",\n    ylab = \"W'keitsdichte\",\n    xlab = \"Anteil G9-Befürworter:innen\",\n    frame.plot = F\n    )\n}\n)\n\n### Plot Prior 2 ###############################################################\noutput$prior2 &lt;- renderPlot({\n\n  p &lt;- seq(0,1, length=1000)\n\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes2()$shape1,\n          prior_shapes2()$shape2),\n    type = 'l',\n    col = \"#bc991b\",\n    ylab = \"W'keitsdichte\",\n    xlab = \"Anteil G9-Befürworter:innen\",\n    frame.plot = F\n    )\n}\n)\n\n\n################################################################################\n### Plot of Likelihoods                                                      ###\n################################################################################\n\n### custom reactive values #####################################################\nN &lt;- reactive({input$prog8 + input$prog9})\n\n\n### compute the bf from marginal likelihoods ##################################\nwkeit1 &lt;- reactive({\n  integral(likelihood(family = \"binomial\", \n                      successes = input$prog9, \n                      trials = input$prog9 + input$prog8)*\n              prior(family = \"beta\", \n                  alpha = prior_shapes1()$shape1, \n                  beta = prior_shapes1()$shape2))\n})\n\nwkeit2 &lt;- reactive({ \n  integral(likelihood(family = \"binomial\", \n                      successes = input$prog9, \n                      trials = input$prog9 + input$prog8)*\n              prior(family = \"beta\", \n                  alpha = prior_shapes2()$shape1, \n                  beta = prior_shapes2()$shape2))\n})\n\n### create data for the two marginal likelihood distributions ####################\ndata &lt;- reactive({\n\ndata_h1 &lt;- tibble(k = 1:N(),\n                  hyp = \"Hypothese 1\")\nfor(i in 1:N()){\ndata_h1$p[i] &lt;- integral(likelihood(family = \"binomial\", \n                         successes = data_h1$k[i], \n                         trials = input$prog9 + input$prog8)*\n                   prior(family = \"beta\", \n                         alpha = prior_shapes1()$shape1, \n                         beta = prior_shapes1()$shape2))\n}\n\ndata_h1 &lt;- data_h1 %&gt;% \n  mutate(obs_eq_k = k == N()) \n\n\ndata_h2 &lt;- tibble(k = 1:N(),\n                  hyp = \"Hypothese 2\")\nfor(i in 1:N()){\ndata_h2$p[i] &lt;- integral(likelihood(family = \"binomial\", \n                         successes = data_h2$k[i], \n                         trials = input$prog9 + input$prog8)*\n                   prior(family = \"beta\", \n                         alpha = prior_shapes2()$shape1, \n                         beta = prior_shapes2()$shape2))\n}\n\ndata_h2 &lt;- data_h2 %&gt;% \n  mutate(obs_eq_k = k == N()) \n\n\n\nreturn(full_join(data_h1, data_h2))\n\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n\n ggplot() +\n    # add whole binomial distributions with alpha\n    geom_segment(data = data() %&gt;% \n                          filter(hyp == \"Hypothese 1\"), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p), \n                 color = \"#bc1b9a50\") +\n    geom_segment(data = data() %&gt;% \n                     filter(hyp == \"Hypothese 2\"), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p), \n                 color = \"#bc991b60\") +\n    # add selected binomial distributions without alpha\n    geom_segment(data = data() %&gt;% \n                     filter(hyp == \"Hypothese 1\" & k == input$prog9), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p, color = \"#bc1b9a\")) +\n    geom_segment(data = data() %&gt;% \n                     filter(hyp == \"Hypothese 2\" & k == input$prog9), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p, color = \"#bc991b\")) +\n    theme_minimal() +\n    geom_text(data = tibble(x = input$prog9, y = -.005, \n                            text = paste(\"BF =\", \n                                         formatC(wkeit1()/wkeit2(), \n                                                 format = \"e\", \n                                                 digits = 2))),\n              aes(x, y, label = text)) +\n    xlab(\"Anzahl\") + ylab(\"Wahrscheinlichkeit\") +\n    ggtitle(\"Berechnung des Bayes-Faktors\", \"bei Punkthypothesen\") +\n    scale_color_identity(name = \"Marginal Likelihood\",\n                         breaks = c(\"#bc1b9a\", \"#bc991b\"),\n                         labels = c(\"Hyp. 1\", \"Hyp 2.\"),\n                         guide = \"legend\") +\n    theme(legend.position = \"bottom\")\n})\n\n### debug ######################################################################\noutput$debug &lt;- renderPrint({\n data()\n})\n\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\nBuergler, S., Sezer, D., Bagge, N., Kirsch, I., Locher, C., Carvalho, C., & Gaab, J. (2023). Imaginary Pills and Open-Label Placebos Can Reduce Test Anxiety by Means of Placebo Mechanisms  Scientific Reports. Scientific Reports, 13(1), 2624.\n\n\nDöring, N., & Bortz, J. (2016). Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften (5., vollst). Berlin, Heidelberg: Springer.\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik Und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\n\n\nGu, X., Hoijtink, H., Mulder, J., & Rosseel, Y. (2019). Bain: A Program for Bayesian Testing of Order Constrained Hypotheses in Structural Equation Models. Journal of Statistical Computation and Simulation, 89(8), 1526–1553.\n\n\nHoijtink, H. (2012). Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists. Boca Raton: CRC.\n\n\nKruschke, J. K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd Aufl.). Academic Press.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis Testing, Estimation, Meta-Analysis, and Power Analysis from a Bayesian Perspective. Psychonomic Bulletin & Review, 25, 178–206.\n\n\nLakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses. Social Psychological and Personality Science, 8(4), 355–362.\n\n\nTendeiro, J. N., Kiers, H. A. L., Hoekstra, R., Wong, T. K., & Morey, R. D. (2024). Diagnosing the Misuse of the Bayes Factor in Applied Research. Advances in Methods and Practices in Psychological Science, 7(1), 25152459231213371.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Hypothesen testen vs. Parameter schätzen</span>"
    ]
  },
  {
    "objectID": "fully_bayesian_estimation.html",
    "href": "fully_bayesian_estimation.html",
    "title": "3  The (Fully) Bayesian Estimation Approach",
    "section": "",
    "text": "3.1 Interaktive Visualisierung\nDer folgenden interaktiven Visualisierung ist als Prior eine Betaverteilung und als Likelihood eine Binomialverteilung vorgegeben. Wendet man Bayes Theorem auf die entsprechenden Funktionsvorschriften an kann man zeigen, dass als Posterior wieder eine Betaverteilung entsteht. Diesen seltenen Fall der analytischen (»geschlossenen«) Lösbarkeit nennt man conjugacy prior (Lambert, 2018).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The (Fully) Bayesian Estimation Approach</span>"
    ]
  },
  {
    "objectID": "fully_bayesian_estimation.html#interaktive-visualisierung",
    "href": "fully_bayesian_estimation.html#interaktive-visualisierung",
    "title": "3  The (Fully) Bayesian Estimation Approach",
    "section": "",
    "text": "Aufgabe Lösungsvorschlag \n\n\nProbiert aus, was in der folgenden interaktiven Visualisierung mit dem Posterior passiert,\n\nwenn ein flacher Prior gewählt ist, der Anteil der G9-Befürworter:innen gleich bleibt, aber die Anzahl der Beobachtungen steigen (also z.B. n₁ = 2 & n₂ = 4; n₁ = 5 & n₂ = 10; n₁ = 23 & n₂ = 46; …)\nwenn ein präziser Prior gewählt ist, und die Anzahl der Beobachtungen klein ist\nwenn ein präziser Prior gewählt ist, dessen Mittelwert »weit« vom Anteil der G9-Befürworter:innen entfernt ist und die Anzahl der Beobachtungen steigen\n\n\n\n\nDer Posterior ist vollständig durch die Daten getrieben. Der Modus des Posteriors ist gleich dem Anteil der G9-Befürworter:innen. Mit steigender Anzahl der Beobachtungen wird der Posterior schmaler, das HDI kleiner.\nDer Posterior ist recht stark durch den Prior geprägt.\nMit steigender Anzahl der Beobachtungen sinkt der Einfluss des Priors.\n\n\n\n\n#| standalone: true\n#| viewerHeight: 800\n\nlibrary(bslib)\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Prior\"),\n         card_body(\n           sliderInput(\n             \"prior_mu\",\n             \"Prior Mean\",\n             min = 0,\n             max = 1,\n             value = .5,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi\",\n             \"Prior Precision\",\n             min = 2,\n             max = 100,\n             value = 3,\n             step = 1\n           )\n         )),\n    card(card_header(class = \"bg-dark\", \"Data\"),\n         card_body(\n           numericInput(\n             \"successes\",\n             \"n₁ = Zustimmung G9\",\n             min = 0,\n             value = 13,\n             step = 1\n           ),\n           numericInput(\n             \"failures\",\n             \"n₂ = Ablehnung G9\",\n             min = 0,\n             value = 8,\n             step = 1\n           )\n         ))), \n  card(card_header(\"Posterior\", class = \"bg-dark\"),\n       card_body(plotOutput(\"plot\")))\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n### custom functions ###########################################################\n# muphi_to_shapes \nmuphi_to_shapes &lt;- function(mu, phi) {\n  shape1 &lt;- mu * phi\n  shape2 &lt;- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n### aux variables ##############################################################\n# convert prior parameterization\n\nprior_shapes &lt;- reactive({\n  muphi_to_shapes(input$prior_mu, input$prior_phi)\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n  \n  # set x-axis\n  p &lt;- seq(0,1, length=1000)\n  \n  # compute max-desity for ylim and legend position\n  density_max &lt;-\n    max(c(\n      dbeta(p,\n            prior_shapes()$shape1,\n            prior_shapes()$shape2),\n      dbeta(\n        p,\n        prior_shapes()$shape1 + input$successes,\n        prior_shapes()$shape2 + input$failures\n      )\n    ))\n  \n  # compute lower bound of 96%-HPDI\n  hpdi_lb &lt;-\n    qbeta(.02,\n           prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  # compute upper bound of 96%-HPDI\n  hpdi_ub &lt;-\n    qbeta(.98,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  \n  # create plot\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes()$shape1,\n          prior_shapes()$shape2),\n    type = 'l',\n    col = \"#1bbc9d\",\n    ylab = \"Wahrscheinlichkeitsdichte\",\n    xlab = \"Anteil G9-Befürworter:innen\",\n    frame.plot = F,\n    ylim = c(0, density_max)\n    )\n  lines(p,\n        dbeta(\n          p,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures\n          ),\n          col = '#EA80FC'\n        )\n  polygon(c(hpdi_lb, hpdi_lb, hpdi_ub, hpdi_ub),\n          c(0, density_max/40, density_max/40, 0),\n          col = \"#EA80FC30\",\n          border = \"#EA80FC00\")\n  legend(\n    bty = \"n\",\n    .8,\n    density_max,\n    c('Prior', 'Posterior', '96% HDI'),\n    lty = c(1, 1, 1),\n    lwd = c(1, 1, 8),\n    col = c('#1bbc9d', '#EA80FC', '#EA80FC30')\n  )\n\n})\n\n### debug ######################################################################\n# output$debug &lt;- renderPrint({\n#   max(c(\n#                dbeta(p, \n#                      prior_shapes()$shape1, \n#                      prior_shapes()$shape2),\n#                dbeta(p, \n#                      prior_shapes()$shape1 + input$successes, \n#                      prior_shapes()$shape2 + input$failures))\n#              )\n#              \n# })\n\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\nLambert, B. (2018). A Student’s Guide to Bayesian Statistics. Los Angeles: SAGE.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The (Fully) Bayesian Estimation Approach</span>"
    ]
  },
  {
    "objectID": "bayesian_gaussian_regression.html",
    "href": "bayesian_gaussian_regression.html",
    "title": "4  Bayesian (Gaussian) Regression",
    "section": "",
    "text": "4.1 Minimalbeispiel\nZentraler Teil des Workshops soll ja die bayesianische Regressionsanalyse sein. Der Begriff »Regression« ist sehr allgemein und umfasst eine Vielzahl von Modellen. In diesem Workshop werden wir mit dem starten, was in vielen sozialwissenschaftlichen Lehrbüchern als »lineare Regression« bezeichnet und oftmals wie folgt notiert wird:\n\\[y_i = b_0 + b_1 x_i + \\epsilon_i\\] \\[\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\]\nIm Kontext bayesianischer Regressionanalyse oder im Kontext des allgemeinen linearen Modells wird oft folgende Notation verwendet: \\[y_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2) \\] \\[\\mu_i = b_0 + b_1 x_i\\]\nDie Idee ist, dass die abhängige Variable \\(y_i\\) normalverteilt ist, wobei der Erwartungswert \\(\\mu_i\\) durch eine lineare Funktion der unabhängigen Variable \\(x_i\\) bestimmt wird. Die Residuen \\(\\epsilon_i\\) sind normalverteilt mit einer konstanten Varianz \\(\\sigma^2\\).\nIn der klassischen linearen Regression wird die Schätzung der Parameter \\(b_0\\) und \\(b_1\\) durch die Methode der kleinsten Quadrate (OLS) durchgeführt. In der bayesianischen Regression wird die Posterior-Verteilung dieser Parameter geschätzt.\nUm ein Gefühl für dieses Verfahren zu bekommen habe ich in den folgenden 3 Beispielen die gleichen wahren Regressionkoeffizienten zugrunde gelegt, für diese aber unterschiedlich viele Daten simuliert. Das wahre Regressionsmodell in lautet (in der Notation von Gelman & Hill Gelman & Hill (2007)):\n\\[y_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2) \\] \\[\\mu_i = 2 + .5 x_i + 0z_i\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Bayesian (Gaussian) Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_gaussian_regression.html#minimalbeispiel",
    "href": "bayesian_gaussian_regression.html#minimalbeispiel",
    "title": "4  Bayesian (Gaussian) Regression",
    "section": "",
    "text": "Beispiel 1: 100 DatenpunkteBeispiel 2: 9 DatenpunkteBeispiel 3: 25 Datenpunkte\n\n\n\n4.1.1 Die Daten\n\n\n\n\n\n\n\n\n\n\n\n4.1.2 Die Posterior-Verteilung der Parameter\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.3 Die Daten\n\n\n\n\n\n\n\n\n\n\n\n4.1.4 Die Posterior-Verteilung der Parameter\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.5 Die Daten\n\n\n\n\n\n\n\n\n\n\n\n4.1.6 Die Posterior-Verteilung der Parameter",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Bayesian (Gaussian) Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_gaussian_regression.html#worked-out-example-woe-1",
    "href": "bayesian_gaussian_regression.html#worked-out-example-woe-1",
    "title": "4  Bayesian (Gaussian) Regression",
    "section": "4.2 Worked out Example (WOE) 1:",
    "text": "4.2 Worked out Example (WOE) 1:\n\n4.2.1 Datengrundlage\nWir verwenden den Datensatz College Success aus der Jasp Data Library. Er wird dort wie folgt beschrieben:\n\n\n\n\n\n\nCollege Success Data \n\n\n\n\n\nThis data set, “College Success”, provides high school grades, SAT scores, and Grade Point Average of 224 university students.\nVariables:\n\nid - Participant ID.\ngpa - Grade Point Average (GPA) after three semester in college.\nhsm - Average high-school grade in mathematics.\nhss - Average high-school grade in science.\nhse - Average high-school grade in English.\nsatm - SAT score for mathematics.\nsatv - SAT score for verbal knowledge.\nsex - Gender (labels not available)\n\n\n\n\n\n\n4.2.2 Datenimport\n\ndata_college_success &lt;- \n  read_csv(\"https://bit.ly/merk-data-college-success\")\n\n\n\n4.2.3 Ein erstes Modell mit {brms}\nZunächst wollen wir ein Modell fitten, das den College Succes (GPA) mit den Schulnoten vorhersagt.\n\nlibrary(brms)\nmod01 &lt;- \n    brm(scale(gpa) ~ scale(hsm) + scale(satm), \n        data = data_college_success,\n        family = gaussian(),\n        cores = 4)\n\nDas Paket {brms} stellt »nur« ein -Interface für die probabilistische Sprache Stan dar. Da keine priors explizit spezifiziert wurden, legt {brms} per default weakly informative Priors fest um aus diesen über die Likelihood der Daten die Posteriorverteilungen der Daten zu ermitteln. Dies geschieht allerdings nicht »geschlossen/analytisch« (also mit »Formeln«) sondern mit einer Monte-Carlo Methode (»Simulation«).\nDie Algorithmen dieser Simulationen sind das computative Nadelöhr bayesianischer Inferenz und das zentrale Entwicklungsfeld mathematisch statistischer Forschung. Wir beschränken uns zunächst darauf, die Diagnostik dieser Simulation durchzuführen. Dazu wendet man die plot-Funktion auf das {brms}-Objekt an.\n\nplot(mod01)\n\n\n\n\n\n\n\n\nDieser Plot zeigt zum einen die Posteriorverteilung der geschätzen Parameter (links) sowie die Trajektorie jeder Chain des Algorithmus (rechts). Diese sollten sich überlappen und jeweils keinen globalenTrend zeigen.\nDer summary-Befehl liefert neben den Parameter und deren Credibility Intervallen zudem Information über die Qualität des Samplings (also der algorithmischen Approximation des Posteriors): Die Effective Sample Size (ESS) beschreibt die Anzahl der Posterior Draws bereinigt um deren Korrelation an. Der \\(\\widehat{R}\\) Wert dagegen vergleicht die Varianz zwischen mehreren Ketten mit der Varianz innerhalb jeder Kette. Wenn alle Ketten zur gleichen Verteilung konvergiert haben, sollten die Varianzen zwischen den Ketten und innerhalb der Ketten ungefähr gleich sein also \\(\\widehat{R}= 1\\). Faustregeln geben of eine \\(ESS &gt; 1000\\) (Bürkner, 2017) und ein \\(\\widehat{R} &lt; 1.05\\) (Vehtari, Gelman, Simpson, Carpenter, & Bürkner, 2021) an. {brms} gibt allerdings auch Warnungen aus, sollten diese Werte problematisch sein.\n\nsummary(mod01)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: scale(gpa) ~ scale(hsm) + scale(satm) \n   Data: data_college_success (Number of observations: 224) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.00      0.06    -0.11     0.12 1.00     4123     2799\nscalehsm      0.41      0.07     0.28     0.54 1.00     3423     2932\nscalesatm     0.07      0.07    -0.06     0.20 1.00     3645     2745\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.91      0.04     0.83     1.00 1.00     4042     2705\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nOft ist es aufschlussreich die Posteriors auf einer gemeinsamen Achse zu plotten:\n\nplot(estimate_density(mod01), stack = F, priors = F) +\n     theme_minimal()\n\n\n\n\n\n\n\nAbbildung 4.1: Testcaption\n\n\n\n\n\nDa die Postriors im Gegensatz zu p-Werten und \\(BF\\) tatsächlich bedingte Wahrscheinlichkeiten der Parameter darstellen, kann man nun ganz easy informative Aussagen machen wie\n\n\n\n\n\n\nEs liegt Evidenz für einen mindestens kleinen Effekt (Cohen, 1988) der Mathematikschulnote vor\n\n\n\n\n\n\nhypothesis(mod01, \"scalehsm &gt; .1\")\n\nHypothesis Tests for class b:\n           Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob\n1 (scalehsm)-(.1) &gt; 0     0.31      0.07     0.19     0.42        Inf         1\n  Star\n1    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\n\n\n\n\n\n\n\n\n\n\nEs liegt Evidenz für einen höchstens kleinen bis moderaten Effekt (Cohen, 1988) des SAT-Mathematikwertes vor\n\n\n\n\n\n\nhypothesis(mod01, \"abs(scalesatm) &lt; .2\")\n\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (abs(scalesatm))-... &lt; 0    -0.12      0.05    -0.19    -0.02      40.24\n  Post.Prob Star\n1      0.98    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\n\n\n\n\n\n\n\n\n\n\nDie Mathematikschulnote zeigte einen größeren Effekt als der Mathematik SAT-Score\n\n\n\n\n\n\nhypothesis(mod01, \"scalesatm &lt; scalehsm\")\n\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (scalesatm)-(scal... &lt; 0    -0.34      0.12    -0.53    -0.15    1332.33\n  Post.Prob Star\n1         1    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\n\n\n\n\nAlle diese Aussagen kann man bereits im Plot der Posteriors (siehe Abbildung 4.1) »mit bloßem 👀« sehen.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Bayesian (Gaussian) Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_gaussian_regression.html#woe-2",
    "href": "bayesian_gaussian_regression.html#woe-2",
    "title": "4  Bayesian (Gaussian) Regression",
    "section": "4.3 WOE 2:",
    "text": "4.3 WOE 2:\n\n4.3.1 Datengrundlage\nAls zweites WOE wollen wir uns die Daten aus Wagenmakers u. a. (2015) anschauen. Dieses Experiment stellt eine Replikation einer Studie dar, die postulierte, dass das »Rückwartsdrehen« von Gegenständen zu weniger »Offenheit« führt. Die Daten sind auf dem Open Science Framework  unter https://osf.io/yvrzw verfügbar und sind dort wie folgt beschrieben\n\n\n\n\n\n\nKitchen Rolls \n\n\n\n\n\nThis data set, »Kitchen Rolls«, provides Openness to Experience scores for two groups of students - while filling out the personality questionnaire, both groups rotated a kitchen roll with their hands (one group clockwise, the other group counterclockwise).\n\nParticipantNumber: participant number\nCondition:\n\n1 = counterclockwise rotation & answeroption “completely disagree” (helemaal oneens) on top of the screen\n2 = clockwise rotation & “completely disagree” (helemaal oneens) on top of the screen\n3 = counterclockwise rotation & “completely agree” (helemaal eens) on top of the screen\n4 = clockwise rotation & “completely agree” (helemaal eens) on top of the screen\n\nq1_check: control question about pleasantness of the task: “How pleasant did you think this task was?” (“Hoe aangenaam vond je deze taak?”) 0 (not at all) (helemaal niet) - 10 (very much) (heel erg)\nq2_check: control question about effort: “Hoeveel moeite kostte deze taak je? 0 (heel weinig) -10 (heel veel)”\nq1_NEO: “I find philosophical discussion boring” (“Ik vind filosofische discussies saai”)\nq2_NEO: “I do not like poetry” (“Poezie doet mij weinig tot niets”)\nq3_NEO: “When I read a poem or look at a work of art, sometimes I feel chills or a wave of excitement” (” Wanneer ik een gedicht lees of naar een kunstwerk kijk, voel ik soms een koude rilling of een golf van opwinding”)\nq4_NEO: “I don’t like to spend my time daydreaming” (“Ik hou er niet van mijn tijd te verdoen met dagdromen”)\nq5_NEO: “I am intrigued by the patterns I find in art and nature” (“Ik ben geintrigeerd door de patronen die ik vind in de kunst en de natuur”)\nq6_NEO: “I think students are only confused and misled by listening to speakers with controversial ideas.” (“Ik vind dat leerlingen alleen maar verward en misleid worden door ze te laten luisteren naar sprekers met controversiele ideeen”)\nq7_NEO: “I often try new and foreign food” (“Ik probeer vaak nieuwe en buitenlandse gerechten”)\nq8_NEO: “I rarely notice de moods or feelings, evoked by different environments” (“Ik merk zelden de stemmingen of gevoelens op, die verschillende omgevingen oproepen”)\nq9_NEO: “I think we can expect decisions regarding moral issues to be taken by our religious leaders” (“Ik vind dat we beslissingen in morele zaken van onze religieuze leiders mogen verwachten”)\nq10_NEO: “I am not very interested in speculating about the nature of the universe or of humankind” (“Ik ben niet erg geinteresseerd in het speculeren over het wezen van het universum of van de mens”)\nq11_NEO: “I am eager to learn” (“Ik ben leergierig”)\nq12_NEO: “I like playing with theories or abstract ideas” (“Ik heb vaak plezier in het spelen met theorieen of abstracte ideeen”)\nmean_NEO: average of the 12 NEO-items. The higher the score, the more openness to experience\nq3_ check: Control question for mood: “At this moment, how do you feel?” (Hoe voel je je op dit moment?“) 0: very bad (heel slecht) - 10: very good (heel goed)\nq4_check: Control question for arousal: “At this moment, how aroused are you?” (“Hoe geprikkeld ben je op dit moment?”) 0: very relaxed (heel ontspannen) - 10 very aroused (heel geprikkeld)\nInclude: TRUE if included in the analysis, FALSE if not (see below for reasons of exclusion)\nRotation: rotation direction (clockwise or counter-clockwise)\nAge: age\nSex: female/male\nStudent: yes if student, no if not\nMajor.Occupation: The major (study) or the occupation of the participants\n\n\n\n\n\n\n4.3.2 Datenimport\n\ndata_kitchen_rolls &lt;- read_csv(\"https://osf.io/download/yvrzw/\")\n\nRows: 102 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Rotation, Sex, Student, Major.Occupation\ndbl (20): ParticipantNumber, Condition, q1_check, q2_check, q1_NEO, q2_NEO, ...\nlgl  (1): Include\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nBürkner, P.-C. (2017). Brms: An R Package for Bayesian Multilevel Models Using Stan. Journal of Statistical Software, 80(1).\n\n\nCohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2. Aufl.). New Jersey: Lawrence Erlbaum.\n\n\nGelman, A., & Hill, J. (2007). Data Analysis Using Regression and Multilevel/Hierarchical Models (Bd. 1). New York, NY: Cambridge University Press.\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., & Bürkner, P.-C. (2021). Rank-Normalization, Folding, and Localization: An Improved R^ for Assessing Convergence of MCMC (with Discussion). Bayesian Analysis, 16(2).\n\n\nWagenmakers, E.-J., Beek, T. F., Rotteveel, M., Gierholz, A., Matzke, D., Steingroever, H., … Pinto, Y. (2015). Turning the Hands of Time Again: A Purely Confirmatory Replication Study and a Bayesian Analysis. Frontiers in Psychology, 6.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Bayesian (Gaussian) Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_poisson_regression.html",
    "href": "bayesian_poisson_regression.html",
    "title": "5  Bayesian Poisson Regression",
    "section": "",
    "text": "5.1 Vergleich von Normal und Poisson Verteilung",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bayesian Poisson Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_poisson_regression.html#vergleich-von-normal-und-poisson-verteilung",
    "href": "bayesian_poisson_regression.html#vergleich-von-normal-und-poisson-verteilung",
    "title": "5  Bayesian Poisson Regression",
    "section": "",
    "text": "Die Poissonverteilung ist eine diskrete Wahrscheinlichkeitsverteilung, die die Anzahl der Ereignisse modelliert, die in einem festen Zeitraum oder in einem festen Intervall auftreten. Die Poissonverteilung hat nur einen Parameter, \\(\\lambda\\), der die durchschnittliche Anzahl der Ereignisse pro Intervall angibt. Die Wahrscheinlichkeitsfunktion der Poissonverteilung ist gegeben durch\n\\[\nP_\\lambda(x)=\\frac{\\lambda^x}{x!} \\mathrm{e}^{-\\lambda}\n\\]\n\njstat = require('jstat')\nimport {Plot} from \"@mkfreeman/plot-tooltip\"\npoispdf = {\n  const x = d3.range(0, params[0] + 4*Math.sqrt(params[0]), 1);\n  const data = x.map(x =&gt; ({x: x, pdf: jstat.poisson.pdf(x, params[0])}));\n  return data\n}\npoiscdf = jstat.poisson.cdf(params[1], params[0]);\nviewof params = Inputs.form([\n      Inputs.range([0.1, 20], {value: 2, step: 0.1, label: tex`\\lambda:`})\n    ])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmoments = tex`\n\\begin{aligned}\n&\\mathrm{E}( X) =  \\lambda = ${params[0].toPrecision(3)} \\\\[0.5em]\n&\\mathrm{Var}( X) =  \\lambda  = ${params[0].toPrecision(3)} \n\\end{aligned}\n`\n\n\n\n\n\n\n\nplt_pdf = Plot.plot({\n    color: { \n      legend: false\n    },\n    x: {\n      label: \"x\",\n      axis: true\n    },\n    y: {\n      label: \"f(x)\",\n      axis: true\n    },\n  tooltip: {\n    fill: \"#1bbc9d\",\n    stroke: \"#1bbc9d\",\n    opacity: 1,\n  },\n    marks: [\n      Plot.ruleY([0]),\n      Plot.barY(poispdf,{x: \"x\", y: \"pdf\", fill: \"#1bbc9d\", strokeWidth: 0, opacity: 1,\n                title: (d) =&gt; `P(X=${d.x}) = ${(d.pdf).toPrecision(4)}`})\n    ]\n  })\n\n\n\n\n\n\n\n\n\nDie Normalverteilung ist eine kontinuierliche Wahrscheinlichkeitsverteilung, die die Addition unendlich vieler gleicher unabhängiger Verteilungen modelliert. Die Normalverteilung hat zwei Parameter, den Erwartungswert \\(\\mu\\) und die Standardabweichung \\(\\sigma\\). Die Wahrscheinlichkeitsfunktion der Normalverteilung ist gegeben durch\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2} \\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n\\]\n\nviewof mu = Inputs.range([-3, 3], {\n  label: tex`\\mu`,\n  value: 0\n})\n\nviewof sigma = Inputs.range([1e-2, 2], {\n  label: tex`\\sigma`,\n  value: 0.4\n})\n\nhtml`&lt;style&gt;\ninput[type=\"range\"] {\n  /* Change the slider track color */\n  -webkit-appearance: none;\n  width: 100%;\n  height: 8px;\n  background: #1bbc9d50;\n  border-radius: 5px;\n  outline: none;\n  opacity: 0.7;\n  transition: opacity .15s ease-in-out;\n}\n\ninput[type=\"range\"]::-webkit-slider-thumb {\n  /* Change the slider thumb color */\n  -webkit-appearance: none;\n  appearance: none;\n  width: 15px;\n  height: 15px;\n  border-radius: 50%;\n  background: #1bbc9d;\n  cursor: pointer;\n}\n&lt;/style&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nchart = {\n  const svg = d3.create(\"svg\").attr(\"width\", width).attr(\"height\", height);\n\n  const xAxis = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0, ${yScale(0)})`)\n    .call(d3.axisBottom(xScale));\n\n  const yAxis = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${xScale(0)}, 0)`)\n    .call(d3.axisLeft(yScale));\n\n  const path = svg\n    .append(\"g\")\n    .append(\"path\")\n    .attr(\"d\", line(data))\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke\", \"#1bbc9d\");\n\n  return svg.node();\n}\n\n\n\n\n\n\n\nline = d3\n  .line()\n  .x((d) =&gt; xScale(d.x))\n  .y((d) =&gt; yScale(d.y))\n  \nyExtent = [0, Math.max(1, normalPdf(0, 0, sigma))]\n\ndata = x.map((x) =&gt; ({\n  x: x,\n  y: normalPdf(x, mu, sigma)\n}))\n\nx = d3\n  .range(numXPoints)\n  .map((i) =&gt; xExtent[0] + (i * (xExtent[1] - xExtent[0])) / (numXPoints - 1))\n  \n  yScale = d3\n  .scaleLinear()\n  .domain(yExtent)\n  .range([height - margin.bottom, margin.top])\n  \n  xScale = d3\n  .scaleLinear()\n  .domain(xExtent)\n  .range([margin.left, width - margin.right])\n  \n  xExtent = [Math.min(-3, mu - 3 * sigma), Math.max(3, mu + 3 * sigma)]\n  \n  margin = ({ top: 40, right: 40, bottom: 40, left: 40 })\n  \n  numXPoints = width / 2\n  \n  normalPdf = function (x, mu, sigma) {\n  return (\n    (1 / (sigma * Math.sqrt(2 * Math.PI))) *\n    Math.exp((-0.5 * Math.pow(x - mu, 2)) / (2 * Math.pow(sigma, 2)))\n  );\n}\n\nwidth = 350\nheight = 350",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bayesian Poisson Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_poisson_regression.html#woe-1-liegestützen",
    "href": "bayesian_poisson_regression.html#woe-1-liegestützen",
    "title": "5  Bayesian Poisson Regression",
    "section": "5.2 WOE 1: Liegestützen",
    "text": "5.2 WOE 1: Liegestützen\n\nlibrary(ggdist)\nlibrary(tidyverse)\nN &lt;- 1000\ndata_lieg &lt;- \n  tibble(Alter_n = round(runif(N, 5, 18), 0),\n         Alter = as.factor(Alter_n),\n         lieg_male = rpois(N, Alter_n + 3) + sample(c(-1,1),1)*rpois(N, 3),\n         lieg_female = lieg_male +sample(c(-1,1),1)*rpois(N, 3)) %&gt;% \n  filter(lieg_male &gt; 0 & lieg_female &gt; 0) %&gt;% \n  pivot_longer(cols = c(lieg_male, lieg_female),\n               names_to = \"Geschlecht\",\n               values_to = \"Liegestutzen\") %&gt;% \n  mutate(Geschlecht = ifelse(Geschlecht == \"lieg_male\",\n                             \"male\", \"female\"))\n\n\n\n\n\n\n\nLiegestützen \n\n\n\n\n\nDieses entlang der MoMo-Studie generierte Datenset enthält die Anzahl der Liegestützen, die von 5-18-jährigen Kindern in einem bestimmten Intervall gelistet werden. Die Daten enthalten die folgenden Variablen:\n\nAlter_n_: Alter der Kinder numric\nAlter: Alter der Kinder factor\nGeschlecht: Geschlecht der Kinder\nLiegestützen: Anzahl der Liegestützen, die von den Kindern gemacht wurden",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bayesian Poisson Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_poisson_regression.html#das-modell",
    "href": "bayesian_poisson_regression.html#das-modell",
    "title": "5  Bayesian Poisson Regression",
    "section": "5.3 Das Modell",
    "text": "5.3 Das Modell\n\\[\nLiegestuetzen_i \\sim \\operatorname{Poisson}(\\lambda_i)\n\\] \\[\n\\operatorname{log}\\left(\\lambda_i\\right) = b_0 + b_1 \\cdot Geschlecht_i + \\dots       \n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bayesian Poisson Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_logistic_regression.html",
    "href": "bayesian_logistic_regression.html",
    "title": "6  Bayesian Logistic Regression",
    "section": "",
    "text": "6.1 WOE 1: Graduate School Admission",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bayesian Logistic Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_logistic_regression.html#woe-1-graduate-school-admission",
    "href": "bayesian_logistic_regression.html#woe-1-graduate-school-admission",
    "title": "6  Bayesian Logistic Regression",
    "section": "",
    "text": "6.1.1 Datengrundlage\nWir verwenden den Datensatz Graduate Schoole Admission aus dem -Paket {ProbBayes}. Er wird dort wie folgt beschrieben:\n\n\n\n\n\n\nGraduate Schoole Admission \n\n\n\n\n\nA data frame with 400 observations on the following 3 variables.\n\nAdmission: student was admitted (1) or not admitted (0)\nGRE: GRE score\nGPA: grade point average\n\n\n\n\n\n\n6.1.2 Datenimport\n\nlibrary(ProbBayes)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bayesian Logistic Regression</span>"
    ]
  },
  {
    "objectID": "bayesian_logistic_regression.html#das-modell",
    "href": "bayesian_logistic_regression.html#das-modell",
    "title": "6  Bayesian Logistic Regression",
    "section": "6.2 Das Modell",
    "text": "6.2 Das Modell\n\\[\nAdmisson_i \\sim \\operatorname{Bernoulli}(\\theta_i)\n\\]\n\\[\n\\begin{aligned}\n\\operatorname{logit}(\\theta_i) &= b_0 + b_1 \\cdot GRE_i + b_2 \\cdot GPA_i \\\\\n\\operatorname{log}\\left( \\frac{\\theta_i}{1-\\theta_i} \\right) &= b_0 + b_1 \\cdot GRE_i + b_2 \\cdot GPA_i\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bayesian Logistic Regression</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Buergler, S., Sezer, D., Bagge, N., Kirsch, I., Locher, C., Carvalho,\nC., & Gaab, J. (2023). Imaginary pills and\nopen-label placebos can reduce test anxiety by means of placebo\nmechanisms  Scientific Reports.\nScientific Reports, 13(1), 2624.\n\n\nBürkner, P.-C. (2017). Brms: An R\nPackage for Bayesian Multilevel Models Using\nStan. Journal of Statistical Software,\n80(1).\n\n\nCohen, J. (1988). Statistical power analysis for the behavioral\nsciences (2nd ed.). New Jersey: Lawrence\nErlbaum.\n\n\nDöring, N., & Bortz, J. (2016). Forschungsmethoden und\nEvaluation in den Sozial- und Humanwissenschaften (5.,\nvollst). Berlin, Heidelberg: Springer.\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und\nForschungsmethoden: Lehrbuch. Mit\nOnline-Materialien (3rd ed.). Beltz.\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression\nand multilevel/hierarchical models (Vol. 1). New York, NY:\nCambridge University Press.\n\n\nGu, X., Hoijtink, H., Mulder, J., & Rosseel, Y. (2019). Bain:\nA program for Bayesian testing of order\nconstrained hypotheses in structural equation models. Journal of\nStatistical Computation and Simulation, 89(8), 1526–1553.\n\n\nHoijtink, H. (2012). Informative hypotheses: Theory and\npractice for behavioral and social scientists. Boca\nRaton: CRC.\n\n\nKruschke, J. K. (2015). Doing Bayesian data analysis:\nA tutorial with R, JAGS, and\nStan (2nd ed.). Academic Press.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). The\nBayesian new statistics: Hypothesis testing,\nestimation, meta-analysis, and power analysis from a\nBayesian perspective. Psychonomic Bulletin &\nReview, 25, 178–206.\n\n\nLakens, D. (2017). Equivalence\nTests: A Practical Primer for t\nTests, Correlations, and\nMeta-Analyses. Social Psychological and Personality\nScience, 8(4), 355–362.\n\n\nLambert, B. (2018). A student’s guide to Bayesian\nstatistics. Los Angeles: SAGE.\n\n\nTendeiro, J. N., Kiers, H. A. L., Hoekstra, R., Wong, T. K., &\nMorey, R. D. (2024). Diagnosing the\nMisuse of the Bayes Factor in Applied\nResearch. Advances in Methods and Practices in\nPsychological Science, 7(1), 25152459231213371.\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., & Bürkner,\nP.-C. (2021). Rank-Normalization,\nFolding, and Localization: An Improved\nR^ for Assessing Convergence of\nMCMC (with Discussion). Bayesian\nAnalysis, 16(2).\n\n\nWagenmakers, E.-J., Beek, T. F., Rotteveel, M., Gierholz, A., Matzke,\nD., Steingroever, H., … Pinto, Y. (2015). Turning the hands of\ntime again: A purely confirmatory replication study and a\nBayesian analysis. Frontiers in Psychology,\n6.",
    "crumbs": [
      "Literatur"
    ]
  }
]