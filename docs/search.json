[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GRAPH Sommerakdemie 24",
    "section": "",
    "text": "Willkommen üëã!\nHier finden sich\n\nErkl√§rungen,\nVideos,\nAufgaben,\nDaten und\nCode\n\nf√ºr unseren Kurs Bayesian Regression Modelling.\nZu Beginn des Kurses bitte ich alle eine aktuelle Version von  und Studio installiert zu haben und au√üerdem - falls noch nicht mit {brms} gearbeitet wurde - dieser Anleitung zur Installation und Verkn√ºpfung des -Paketes {brms} zu folgen. Bei Problemen bitte gerne bei mir vorab melden!",
    "crumbs": [
      "Willkommen üëã!"
    ]
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "1¬† Regressionsmodelle",
    "section": "",
    "text": "1.1 Einfache lineare Regression\nIn diesem Unterkapitel soll in die einfache lineare Regression eingef√ºhrt werden. Dazu dient ein Erkl√§rvideo gefolgt von Aufgaben.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#einfache-lineare-regression",
    "href": "regression.html#einfache-lineare-regression",
    "title": "1¬† Regressionsmodelle",
    "section": "",
    "text": "1.1.1 Erkl√§rvideo\n\n\n\n\n\n\n\n\n\n\n\nDatengrundlage\n\n\n\n\n\nWir werden in diesen Workshop mit den Scientific Usefiles des STAR-Projektes (Achilles u.¬†a. 1985) arbeiten. Im STAR-Projekt standen die folgenden Forschungsfragen im Vordergrund:\n\nWhat are the effects of a reduced class size on the achievement (normed and criterion tests) and development (self-concept, attendance, etc.) of students in public elementary school grades (K-3)?\nIs there a cumulative effects of being in a small class over an extended time (4 years) as compared with a one-year effect for students in a small class for one year?\nDoes a training program designed to help teachers take maximum advantage of small classes, or to use aides effectively, improve student performance as compared with teachers who have no special preparation for their altered conditions?\n\nDie entsprechenden Variablenbezeichnungen sowie die Kodierung der Variablenauspr√§gungen werden in den jeweiligen Beispielen beschrieben.\n\n\n\n\n\n1.1.2 Worked Out Example\nIm ersten Worked Out Example wollen wir der Frage nachgehen, inwiefern die tats√§chliche Klassengr√∂√üe mit der Leistung in einem standardisierten Mathematiktest assoziiert ist.\n\n1.1.2.1 Plot\nIn einem ersten Schritt (der ganz generell im zu empfehlen ist) plotten wir die Rohdaten. Um keine Probleme mit geclusterten Daten zu bekommen, verwenden wir aus jeder Klasse nur eine:n zuf√§llig gezogenen Sch√ºler:in. Ein .sav-file, das die notwendigen Variablen enth√§lt, kann hier heruntergeladen werden.\n\nlibrary(sjPlot)\nlibrary(bayestestR)\n\n# read the aggregated data\ndata_star_g3aggregated &lt;- read_spss(\"data/data_star_sampled.sav\")\n\n# plot rawdata\nggplot(data_star_g3aggregated,                       # the used data set\n       aes(g3classsize, g3tmathss)) +                # define x- and y-axis\n    geom_jitter() +                                  # add jittered points\n    geom_rug(position = position_jitter(), \n             alpha = .2) +                           # add rug at margins\n    stat_smooth(method = \"linear\") +                 # add linear smoother\n    theme_minimal()                                  # make appearance \"clearer\"\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 37 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Computation failed in `stat_smooth()`\nCaused by error in `get()`:\n! object 'linear' of mode 'function' was not found\n\n\nWarning: Removed 37 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n1.1.2.2 Nicht-Standardisierte Regression\nUm nun eine einfache lineare Regression zu sch√§tzen, verwendet man in R die lm() Syntax. Links der Tilde ~ steht die abh√§ngige Variable, rechts davon die unabh√§ngige.\n\nmod00 &lt;- lm(g3tmathss ~ g3classsize, \n            data = data_star_g3aggregated)\n\nEine √úbersicht √ºber das Modell bekommt man, wenn man das Objekt mod00 der der Funktion summary() √ºbergibt.\n\nsummary(mod00)\n\n\nCall:\nlm(formula = g3tmathss ~ g3classsize, data = data_star_g3aggregated)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-109.454  -29.725   -0.446   28.743  102.955 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 642.8773    10.1681  63.225   &lt;2e-16 ***\ng3classsize  -0.9015     0.4939  -1.825   0.0689 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.54 on 298 degrees of freedom\n  (37 observations deleted due to missingness)\nMultiple R-squared:  0.01106,   Adjusted R-squared:  0.007739 \nF-statistic: 3.332 on 1 and 298 DF,  p-value: 0.06895\n\n\nDie (lineare) Funktionsgleichung kann man sich mit der Funktion extract_eq() aus dem Paket equatiomatic ausgeben lassen. Mit der Option use_coefs = T setzt man die gesch√§tzten Werte f√ºr die Parameter ein.\n\nlibrary(equatiomatic)\nextract_eq(mod00)\n\n\\[\n\\operatorname{g3tmathss} = \\alpha + \\beta_{1}(\\operatorname{g3classsize}) + \\epsilon\n\\]\n\nextract_eq(mod00, use_coefs = T)\n\n\\[\n\\operatorname{\\widehat{g3tmathss}} = 642.88 - 0.9(\\operatorname{g3classsize})\n\\]\n\n\nDer Steigungskoeffizient betr√§gt \\(\\approx .99\\). Unterscheiden sich zwei Klassen um eine:n Sch√ºler:in sch√§tzt das Modell die Differenz im Mathematikscore auf \\(-.99\\). Das Intercept wird auf \\(638.9\\) gesch√§tzt. Eine (hypothetische) Klasse mit 0 Sch√ºler:innen h√§tte also einen Durchschnittlichen Mathematikleistungsscore von \\(638.9\\).\nDie drei Sternchen am rechten Rand des summary() Outputs zeigen an, dass p-Werte f√ºr die Punktnullhypothesen \\[\nH_0\\text{: Intercept} = 0\n\\] \\[\nH_0\\text{: Slope} = 0\n\\] signifikant sind. Es macht also Sinn diese zu verwerfen.\n\n\n1.1.2.3 Standardisierte Regression\nEine standardisierte lineare Regression setzt wie im Video erkl√§rt voraus, dass alle Variablen z-standardisiert sind. Liegen unvollst√§ndige Daten vor, **ist es wichtig diese Standardisierung erst nach dem fallweisen Ausschluss dieser fehlenden Daten zu tun.\n\nmod01 &lt;- lm(scale(g3tmathss) ~ scale(g3classsize), \n            data = data_star_g3aggregated |&gt; \n                # filter rows if g3tmathss or g3classsize is NA\n                filter(!(is.na(g3tmathss) | is.na(g3classsize))))\nsummary(mod01)\n\n\nCall:\nlm(formula = scale(g3tmathss) ~ scale(g3classsize), data = filter(data_star_g3aggregated, \n    !(is.na(g3tmathss) | is.na(g3classsize))))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.82930 -0.76836 -0.01154  0.74300  2.66132 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)         4.284e-16  5.751e-02   0.000   1.0000  \nscale(g3classsize) -1.052e-01  5.761e-02  -1.825   0.0689 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9961 on 298 degrees of freedom\nMultiple R-squared:  0.01106,   Adjusted R-squared:  0.007739 \nF-statistic: 3.332 on 1 and 298 DF,  p-value: 0.06895\n\nextract_eq(mod01, use_coefs = T)\n\n\\[\n\\operatorname{\\widehat{scale(g3tmathss)}} = 0 - 0.11(\\operatorname{scale(g3classsize)})\n\\]\n\n\nDas Intercept wird auf einen Wert mit 14 Nullen nach dem Komma gesch√§tzt, ist also erwartungskonform quasi gleich null und nicht-signifikant. Der Steigungskoeffizient betr√§gt \\(\\approx .20\\) und liegt nach den Cohen Benchmarks (Cohen 1988) im Bereich kleiner bis moderater Effekte.\nEs gibt Pakete, die darauf spezialisiert sind (mehrere) Regressionsmodelle zusammengefasst √ºbersichtlich in Tabellen darzustellen. Mit der folgenden Syntax bekommt man etwa nicht nur standardisierte und unstandardisierte Koeffizienten, sondern auch deren Konfidenzintervalle, beides auf eine sinnvolle Nachkommestellenanzahl gerundet:\n\nlibrary(sjPlot)\ntab_model(mod00, show.ci = .95, show.std = T)\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\nPredictors\nEstimates\nstd. Beta\nCI\nstandardized CI\np\n\n\n(Intercept)\n642.88\n0.00\n622.87¬†‚Äì¬†662.89\n-0.11¬†‚Äì¬†0.11\n&lt;0.001\n\n\nCLASS SIZE GRADE 3\n-0.90\n-0.11\n-1.87¬†‚Äì¬†0.07\n-0.22¬†‚Äì¬†0.01\n0.069\n\n\nObservations\n300\n\n\nR2 / R2 adjusted\n0.011 / 0.008",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#aufgabe",
    "href": "regression.html#aufgabe",
    "title": "1¬† Regressionsmodelle",
    "section": "1.2 Aufgabe",
    "text": "1.2 Aufgabe\n\nAufgabeL√∂sungshinweiseL√∂sung\n\n\nDas STAR-Experiment variierte die Klassengr√∂√üen experimentell in K, G1, G2, G3 & G4. Daten wurden aber bis zu High School erhoben.\nDie Variable g4tmathss etwa erfasst die Mathematikleistung in Klasse 4, die Variablen g4pteffr und g4ptvalu den von Lehrkr√§ften eingesch√§tzte schulische Leistungsbereitschaft bzw. die Wertsch√§tzung schulischer Inhalte.\nWie gro√ü sch√§tzen Sie die Effekte der Pr√§diktoren g4pteffr und g4ptvalu ein? Sch√§tzen Sie standardisierte und nicht-standardisierte Regressionsmodelle und diskutieren Sie die interne, externe und Konstruktvalidit√§t der so erhaltenen Befunde.\n\n\n\nlibrary(haven)\nlibrary(sjPlot)\ndata_star_sampled &lt;- read_spss(\"data/data_star_sampled.sav\")\n\nmod02 &lt;- lm(g4tmathss ~ g4pteffr, data = data_star_sampled)\nmod03 &lt;- lm(g4tmathss ~ g4ptvalu, data = data_star_sampled)\n\ntab_model(mod02, mod03, show.std = T, show.ci = F)\n\n\n\n\ntab_model(mod02, mod03, show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n595.70\n0.00\n&lt;0.001\n623.37\n0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE:EFFORT\n2.44\n0.60\n&lt;0.001\n\n\n\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE:VALUE\n\n\n\n7.07\n0.37\n&lt;0.001\n\n\nObservations\n106\n106\n\n\nR2 / R2 adjusted\n0.357 / 0.351\n0.137 / 0.129\n\n\n\n\n\n\n\nDer standardisierte Regressionskoeffizient der Effort-Skala ist mit .58 enorm gro√ü ausgepr√§gt und auch der Effekt des Pr√§diktors value ist substantiell. Beachtet werden muss allerdings, dass die p-Werte nichts √ºber die Sicherheit der Unterschiedlichkeit der beiden Steigungsparameter aussagt. Getestet wurde jeweils wieder nur die Nullhypothese eines Nulleffekts. Zu kritisieren sind hier sicher interne und Konstruktvalidit√§t. Effort und Value der Sch√ºler:innen wurden von den Lehrkr√§ften ohne vorherige Raterschulung eingesch√§tzt. Daher ist anzunehmen, dass dieses Rating auch durch die Leistung der Sch√ºler:innen verzerrt ist (z.B. im Sinne eines Haloeffekts, Dennis 2007). Die interne Validit√§t der Schlussfolgerung aus diesen Regressionsmodellen ist schwach, da es sich nur um querschnittliche Daten handelt und die Auspr√§gung der unabh√§ngigen Variable nicht randomisiert wurde.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#multiple-lineare-regression",
    "href": "regression.html#multiple-lineare-regression",
    "title": "1¬† Regressionsmodelle",
    "section": "1.3 Multiple lineare Regression",
    "text": "1.3 Multiple lineare Regression\nIn diesem Unterkapitel soll in die multiple Regression eingef√ºhrt werden. Dazu dient ebenfalls ein Erkl√§rvideo gefolgt von Aufgaben.\n\n1.3.1 Erkl√§rvideo 1\n\n\n\n\n\n\n\n1.3.2 Erkl√§rvideo 2\nDie standardisierten Steigungskoeffizeinten \\(\\beta_i\\) stellen ja eine Effektst√§rke der partiellen Assoziation des Pr√§diktors \\(i\\) mit der abh√§ngigen Variable dar. Nimmt man mehrere Pr√§diktoren auf, kann der Determinationskoeffizient \\(R^2\\) eine Effektst√§rke f√ºr die G√ºte des Gesamtmodells darstellen.\n\n\n\n\n\n\n\n1.3.3 Worked Out Example\nIn der √úbungsaufgabe zur einfachen linearen Regression haben wir vermutet, dass Einsch√§tzung von Effort und Value durch die Lehrkraft von der Leistung der Lernenden gef√§rbt sein k√∂nnte. W√§re dem so, sollte man ein Sinken der Pr√§diktionskraft des Pr√§diktors Value nach Adjustierung um die Vorjahresleistung beobachten.\n\ntab_model(\n    lm(g4tmathss ~ g4ptvalu, data = data_star_sampled),\n    lm(g4tmathss ~ g4ptvalu + g3tmathss, data = data_star_sampled),\n    show.ci = F, show.std = T\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n623.37\n0.00\n&lt;0.001\n183.81\n-0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE:VALUE\n7.07\n0.37\n&lt;0.001\n1.37\n0.07\n0.332\n\n\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\n\n0.81\n0.70\n&lt;0.001\n\n\nObservations\n106\n103\n\n\nR2 / R2 adjusted\n0.137 / 0.129\n0.536 / 0.527\n\n\n\n\n\n\n\nDies ist tats√§chlich der Fall. Der standardisierte Regressionskoeffizient sinkt von .45 auf .18.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#aufgabe-2",
    "href": "regression.html#aufgabe-2",
    "title": "1¬† Regressionsmodelle",
    "section": "1.4 Aufgabe",
    "text": "1.4 Aufgabe\n\nAufgabeL√∂sungshinweiseL√∂sung\n\n\nUntersuchen Sie, inwiefern die ebenfalls Lehrer:inneingesch√§tzte Variable Initiative (z.B. ‚Äúparticipates actively in class discussions‚Äù) g4ptinit die Mathematikleistung in Klasse 4 g4tmathss pr√§diziert und inwiefern sich der Effekt nach Adjustierung der Vortestleistung g3tmathss √§ndernt\n\n\n\nlm(g4tmathss ~ g4ptinit, data = data_star_sampled)\nlm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled)\n\n\n\n\ntab_model(\n    lm(g4tmathss ~ g4ptinit, data = data_star_sampled),\n    lm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled),\n    show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n607.56\n0.00\n&lt;0.001\n255.34\n-0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE:INITIATIVE\n3.89\n0.64\n&lt;0.001\n1.73\n0.28\n0.001\n\n\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\n\n0.65\n0.56\n&lt;0.001\n\n\nObservations\n106\n103\n\n\nR2 / R2 adjusted\n0.405 / 0.399\n0.583 / 0.575\n\n\n\n\n\n\n\nDer standardisierte Regressionskoeffizient der Initiative-Skala ist mit .49 gro√ü ausgepr√§gt. Nach Adjustierung um die Vorjahrestestleistung, sinkt die pr√§diktive Kraft deutlich, es ist aber weiterhin ein substantieller Effekt zu beobachten.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#weiterf√ºhrende-literatur",
    "href": "regression.html#weiterf√ºhrende-literatur",
    "title": "1¬† Regressionsmodelle",
    "section": "1.5 Weiterf√ºhrende Literatur",
    "text": "1.5 Weiterf√ºhrende Literatur\n\n\n\n\n\n\nLiteraturempfehlungen zum Thema Regression\n\n\n\n\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories (1. Aufl.). Cambridge University Press. https://doi.org/10.1017/9781139161879\n\n\n\n\n\n\n\n\nAchilles, C. M., Helen Pate Bain, F. Bellot, J. Boyd-Zaharias, J. Finn, J. Folger, John Johnston, und Elizabeth Word. 1985. ‚ÄûThe State of Tennessee‚Äôs Student/Teacher Achievement Ratio (STAR) Project‚Äú. Technical {{Report}}. Tennessee State Department of Educatbn.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2. Aufl. New Jersey: Lawrence Erlbaum.\n\n\nDennis, Ian. 2007. ‚ÄûHalo Effects in Grading Student Projects‚Äú. Journal of Applied Psychology 92 (4): 1169‚Äì76. https://doi.org/10.1037/0021-9010.92.4.1169.\n\n\nMoosbrugger, Helfried. 2011. Lineare Modelle: Regressions- und Varianzanalysen ; mit einem Anhang √ºber Matrixalgebra. 4., vollst√§ndig √ºberarbeitete und erg√§nzte Auflage. Psychologie Lehrtexte. Bern: Verlag Hans Huber.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "cfa.html",
    "href": "cfa.html",
    "title": "2¬† Confirmatory Factor Analysis",
    "section": "",
    "text": "2.1 Items der Participation Subskalen\nDie Items der beiden Skalen haben die folgenden Bezeichnungen:",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#items-der-participation-subskalen",
    "href": "cfa.html#items-der-participation-subskalen",
    "title": "2¬† Confirmatory Factor Analysis",
    "section": "",
    "text": "Effort\n\ng4ptattn: Grade 4 Participation: Pays attention in class\ng8peattn: Grade 8 Participation, English: Pays attention in class\ng8pmattn: Grade 8 Participation, Mathematics: Pays attention in class\ng4ptmtrl: Grade 4 Participation: Loses materials\ng8pemtrl: Grade 8 Participation, English: Loses materials\ng8pmmtrl: Grade 8 Participation, Mathematics: Loses materials\ng4ptpers: Grade 4 Participation: Is persistent\ng8pepers: Grade 8 Participation, English: Is persistent\ng8pmpers: Grade 8 Participation, Mathematics: Is persistent\ng4ptlate: Grade 4 Participation: Comes late to class\ng8pelate: Grade 8 Participation, English: Comes late to class\ng8pmlate: Grade 8 Participation, Mathematics: Comes late to class\n\nInitiative\n\ng4ptmore: Grade 4 Participation: Does extra work\ng8pemore: Grade 8 Participation, English: Does more than assigned work\ng8pmmore: Grade 8 Participation, Mathematics: Does more than assigned work\ng4ptdisc: Grade 4 Participation: Participates in discussions\ng8pedisc: Grade 8 Participation, English: Participates in discussions\ng8pmdisc: Grade 8 Participation, Mathematics: Participates in discussions\ng4ptdiss: Grade 4 Participation: Discusses subject matter outside of class \ng8pediss: Grade 8 Participation, English: Discusses subject matter outside of class\ng8pmdiss: Grade 8 Participation, Mathematics: Discusses subject matter outside of class",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#formelsprache-in-lavaan",
    "href": "cfa.html#formelsprache-in-lavaan",
    "title": "2¬† Confirmatory Factor Analysis",
    "section": "2.2 Formelsprache in lavaan",
    "text": "2.2 Formelsprache in lavaan\nMit ?model.syntax kann man den folgenden Hilfetext zur Formelsprache in lavaan erhalten:\n\n\n\n\n\n\nFormula-Like Expressions\n\n\n\n\n\nThere can be seven types of formula-like expressions in the model syntax:\n\nLatent variable definitions: The ‚Äú=~‚Äù operator can be used to define (continuous) latent variables. The name of the latent variable is on the left of the ‚Äú=~‚Äù operator, while the terms on the right, separated by ‚Äú+‚Äù operators, are the indicators of the latent variable. The operator ‚Äú=~‚Äù can be read as ‚Äúis manifested by‚Äù.\nRegressions: The ‚Äú~‚Äù operator specifies a regression. The dependent variable is on the left of a ‚Äú~‚Äù operator and the independent variables, separated by ‚Äú+‚Äù operators, are on the right. These regression formulas are similar to the way ordinary linear regression formulas are used in R, but they may include latent variables. Interaction terms are currently not supported.\nVariance-covariances: The ‚Äú~~‚Äù (‚Äòdouble tilde‚Äô) operator specifies (residual) variances of an observed or latent variable, or a set of covariances between one variable, and several other variables (either observed or latent). Several variables, separated by ‚Äú+‚Äù operators can appear on the right. This way, several pairwise (co)variances involving the same left-hand variable can be expressed in a single expression. The distinction between variances and residual variances is made automatically.\nIntercepts: A special case of a regression formula can be used to specify an intercept (or a mean) of either an observed or a latent variable. The variable name is on the left of a ‚Äú~‚Äù operator. On the right is only the number ‚Äú1‚Äù representing the intercept. Including an intercept formula in the model automatically implies meanstructure = TRUE. The distinction between intercepts and means is made automatically.\nThresholds: The ‚Äú|‚Äù operator can be used to define the thresholds of categorical endogenous variables (on the left hand side of the operator). By convention, the thresholds (on the right hand sided, separated by the ‚Äú+‚Äù operator, are named ‚Äút1‚Äù, ‚Äút2‚Äù, etcetera.\nScaling factors: The ‚Äú~*~‚Äù operator defines a scale factor. The variable name on the left hand side must be the same as the variable name on the right hand side. Scale factors are used in the Delta parameterization, in a multiple group analysis when factor indicators are categorical.\nFormative factors: The ‚Äú&lt;~‚Äù operator can be used to define a formative factor (on the right hand side of the operator), in a similar way to how a reflexive factor is defined (using the ‚Äú=~‚Äù operator). This is just syntax sugar to define a phantom latent variable (equivalent to using ‚Äúf =~ 0‚Äù). And in addition, the (residual) variance of the formative factor is fixed to zero.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#ein-erstes-cfa-modell",
    "href": "cfa.html#ein-erstes-cfa-modell",
    "title": "2¬† Confirmatory Factor Analysis",
    "section": "2.3 Ein erstes CFA-Modell",
    "text": "2.3 Ein erstes CFA-Modell\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(lavaan)\nlibrary(semTools)\n\n# read selected variables\ndata_star_selected_variables &lt;- \n    read_spss(\"data/data_star_selected_variables.sav\")\n\n# specifiy which item loads on which latent variable\npart4_mod0 &lt;- \"part =~ g4ptattn + g4ptmtrl + g4ptpers + g4ptlate + g4ptmore + g4ptdisc + g4ptdiss\"\n\npart4_mod1 &lt;- \"eff =~ g4ptattn + g4ptmtrl + g4ptpers + g4ptlate\n               init =~ g4ptmore + g4ptdisc + g4ptdiss\"\n\npart4_fit0 &lt;- cfa(part4_mod0, data = data_star_selected_variables)\npart4_fit1 &lt;- cfa(part4_mod1, data = data_star_selected_variables)\n\nsummary(compareFit(part4_fit0, part4_fit1, nested = T))\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n           Df   AIC   BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \npart4_fit1 13 42956 43042 274.60                                          \npart4_fit0 14 43089 43168 408.97     134.37 0.24555       1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n              chisq df pvalue rmsea   cfi   tli  srmr        aic        bic\npart4_fit1 274.601‚Ä† 13   .000 .095‚Ä† .949‚Ä† .917‚Ä† .045‚Ä† 42956.157‚Ä† 43041.682‚Ä†\npart4_fit0 408.969  14   .000 .113  .922  .883  .053  43088.526  43168.349 \n\n################## Differences in Fit Indices #######################\n                        df rmsea    cfi    tli  srmr     aic     bic\npart4_fit0 - part4_fit1  1 0.018 -0.026 -0.033 0.008 132.369 126.667\n\nlibrary(semPlot)\nsemPaths(part4_fit1, what = \"est\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiteraturempfehlungen zum Thema CFA\n\n\n\n\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\nSacha Epskamp (Regisseur). (2019, April 5). SEM1 (2019)‚ÄîStats recap. https://www.youtube.com/watch?v=fGdsiugwO0k\nBrown, T. A. (2015). Confirmatory factor analysis for applied research. Guilford Press.\n\n\n\n\n\n\n\n\nD√∂ring, Nicola, und J√ºrgen Bortz. 2016. Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften. 5., vollst. Berlin, Heidelberg: Springer.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html",
    "href": "longitudinal_measurement_invariance.html",
    "title": "3¬† L√§ngsschnittliche Messinvarianz",
    "section": "",
    "text": "3.1 Konfigurale Invarianz\nKonfigurale Invarianz pr√ºft ob die Dimensionalit√§t √ºber die Zeit erhalten bleibt. Daher spezifiziert man ein Modell das diese Anforderung erf√ºllt und evaluiert dessen absoluten Fit oder man vergleicht dieses Modell mit plausiblen Modellen, die diese Anforderung nicht erf√ºllen.\nlibrary(lavaan)\n\nWarning: package 'lavaan' was built under R version 4.2.3\n\n\nThis is lavaan 0.6-17\nlavaan is FREE software! Please report any bugs.\n\nlibrary(semTools)\n\n \n\n\n###############################################################################\n\n\nThis is semTools 0.5-6\n\n\nAll users of R (or SEM) are invited to submit functions or ideas for functions.\n\n\n###############################################################################\n\nlibrary(semPlot)\nlibrary(haven)\n\nWarning: package 'haven' was built under R version 4.2.3\n\n# read complete data\ndata_star_selected_variables &lt;- read_spss(\"data/data_star_selected_variables.sav\")\n\n# specify model with same structure at both times\n\npart_configinv_mod &lt;- \n  \"part4e =~ g4ptattn + g4ptmtrl + g4ptpers + g4ptlate\n   part8e =~ g8peattn + g8pemtrl + g8pepers + g8pelate\n\n   # latent (co-)variances\n   part4e ~~ part4e\n   part8e ~~ part8e\n   part4e ~~ part8e\n   \n   # residual variances\n   g4ptattn ~~ g4ptattn\n   g4ptmtrl ~~ g4ptmtrl\n   g4ptpers ~~ g4ptpers\n   g4ptlate ~~ g4ptlate\n   g8peattn ~~ g8peattn\n   g8pemtrl ~~ g8pemtrl\n   g8pepers ~~ g8pepers\n   g8pelate ~~ g8pelate\n   \n   # set residual covariances free over time per indicator\n   g4ptattn ~~ g8peattn\n   g4ptmtrl ~~ g8pemtrl\n   g4ptpers ~~ g8pepers\n   g4ptlate ~~ g8pelate\n   \"\n\n# fit the model to the data aka compare modelimplied and\n# empirical variance-covariance structure\n\npart_configinv_fit &lt;- \n    cfa(part_configinv_mod, data = data_star_selected_variables)\n\nsemPaths(part_configinv_fit, what=\"std\")\n\n\n\n\n\n\n\nparameterestimates(part_configinv_fit, standardized = T)\n\n        lhs op      rhs   est    se      z pvalue ci.lower ci.upper std.lv\n1    part4e =~ g4ptattn 1.000 0.000     NA     NA    1.000    1.000  0.783\n2    part4e =~ g4ptmtrl 0.927 0.058 16.081  0.000    0.814    1.040  0.726\n3    part4e =~ g4ptpers 0.890 0.058 15.251  0.000    0.775    1.004  0.696\n4    part4e =~ g4ptlate 0.411 0.039 10.630  0.000    0.335    0.486  0.321\n5    part8e =~ g8peattn 1.000 0.000     NA     NA    1.000    1.000  0.721\n6    part8e =~ g8pemtrl 1.039 0.054 19.362  0.000    0.934    1.145  0.749\n7    part8e =~ g8pepers 0.951 0.053 17.991  0.000    0.847    1.054  0.685\n8    part8e =~ g8pelate 0.562 0.039 14.419  0.000    0.485    0.638  0.405\n9    part4e ~~   part4e 0.612 0.047 13.123  0.000    0.521    0.704  1.000\n10   part8e ~~   part8e 0.519 0.037 13.918  0.000    0.446    0.593  1.000\n11   part4e ~~   part8e 0.271 0.026 10.567  0.000    0.221    0.321  0.481\n12 g4ptattn ~~ g4ptattn 0.226 0.032  7.180  0.000    0.165    0.288  0.226\n13 g4ptmtrl ~~ g4ptmtrl 0.812 0.045 17.923  0.000    0.724    0.901  0.812\n14 g4ptpers ~~ g4ptpers 0.936 0.049 19.005  0.000    0.839    1.032  0.936\n15 g4ptlate ~~ g4ptlate 0.608 0.028 21.532  0.000    0.553    0.663  0.608\n16 g8peattn ~~ g8peattn 0.217 0.023  9.619  0.000    0.173    0.261  0.217\n17 g8pemtrl ~~ g8pemtrl 0.599 0.035 16.969  0.000    0.530    0.668  0.599\n18 g8pepers ~~ g8pepers 0.692 0.037 18.678  0.000    0.620    0.765  0.692\n19 g8pelate ~~ g8pelate 0.494 0.024 20.767  0.000    0.447    0.541  0.494\n20 g4ptattn ~~ g8peattn 0.006 0.015  0.372  0.710   -0.024    0.035  0.006\n21 g4ptmtrl ~~ g8pemtrl 0.093 0.027  3.493  0.000    0.041    0.145  0.093\n22 g4ptpers ~~ g8pepers 0.012 0.029  0.415  0.678   -0.045    0.069  0.012\n23 g4ptlate ~~ g8pelate 0.058 0.018  3.184  0.001    0.022    0.094  0.058\n   std.all std.nox\n1    0.854   0.854\n2    0.627   0.627\n3    0.584   0.584\n4    0.381   0.381\n5    0.840   0.840\n6    0.696   0.696\n7    0.636   0.636\n8    0.499   0.499\n9    1.000   1.000\n10   1.000   1.000\n11   0.481   0.481\n12   0.270   0.270\n13   0.607   0.607\n14   0.659   0.659\n15   0.855   0.855\n16   0.295   0.295\n17   0.516   0.516\n18   0.596   0.596\n19   0.751   0.751\n20   0.025   0.025\n21   0.133   0.133\n22   0.015   0.015\n23   0.106   0.106\n\nsummary(part_configinv_fit, rsquare = T)\n\nlavaan 0.6.17 ended normally after 25 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        21\n\n                                                  Used       Total\n  Number of observations                          1013       11601\n\nModel Test User Model:\n                                                      \n  Test statistic                                58.125\n  Degrees of freedom                                15\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  part4e =~                                           \n    g4ptattn          1.000                           \n    g4ptmtrl          0.927    0.058   16.081    0.000\n    g4ptpers          0.890    0.058   15.251    0.000\n    g4ptlate          0.411    0.039   10.630    0.000\n  part8e =~                                           \n    g8peattn          1.000                           \n    g8pemtrl          1.039    0.054   19.362    0.000\n    g8pepers          0.951    0.053   17.991    0.000\n    g8pelate          0.562    0.039   14.419    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  part4e ~~                                           \n    part8e            0.271    0.026   10.567    0.000\n .g4ptattn ~~                                         \n   .g8peattn          0.006    0.015    0.372    0.710\n .g4ptmtrl ~~                                         \n   .g8pemtrl          0.093    0.027    3.493    0.000\n .g4ptpers ~~                                         \n   .g8pepers          0.012    0.029    0.415    0.678\n .g4ptlate ~~                                         \n   .g8pelate          0.058    0.018    3.184    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    part4e            0.612    0.047   13.123    0.000\n    part8e            0.519    0.037   13.918    0.000\n   .g4ptattn          0.226    0.032    7.180    0.000\n   .g4ptmtrl          0.812    0.045   17.923    0.000\n   .g4ptpers          0.936    0.049   19.005    0.000\n   .g4ptlate          0.608    0.028   21.532    0.000\n   .g8peattn          0.217    0.023    9.619    0.000\n   .g8pemtrl          0.599    0.035   16.969    0.000\n   .g8pepers          0.692    0.037   18.678    0.000\n   .g8pelate          0.494    0.024   20.767    0.000\n\nR-Square:\n                   Estimate\n    g4ptattn          0.730\n    g4ptmtrl          0.393\n    g4ptpers          0.341\n    g4ptlate          0.145\n    g8peattn          0.705\n    g8pemtrl          0.484\n    g8pepers          0.404\n    g8pelate          0.249",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>L√§ngsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html#schwache-invarianz",
    "href": "longitudinal_measurement_invariance.html#schwache-invarianz",
    "title": "3¬† L√§ngsschnittliche Messinvarianz",
    "section": "3.2 Schwache Invarianz",
    "text": "3.2 Schwache Invarianz\nSchwache\n\npart_weakinv_mod &lt;- \n  \"part4e =~ g4ptattn + s1*g4ptmtrl + s2*g4ptpers + s3*g4ptlate \n   part8e =~ g8peattn + s1*g8pemtrl + s2*g8pepers + s3*g8pelate\n\n   # latent (co-)variances\n   part4e ~~ part4e\n   part8e ~~ part8e\n   part4e ~~ part8e\n   \n   # residual variances\n   g4ptattn ~~ g4ptattn\n   g4ptmtrl ~~ g4ptmtrl\n   g4ptpers ~~ g4ptpers\n   g4ptlate ~~ g4ptlate\n   g8peattn ~~ g8peattn\n   g8pemtrl ~~ g8pemtrl\n   g8pepers ~~ g8pepers\n   g8pelate ~~ g8pelate\n   \n   # set residual covariances free over time per indicator\n   g4ptattn ~~ g8peattn\n   g4ptmtrl ~~ g8pemtrl\n   g4ptpers ~~ g8pepers\n   g4ptlate ~~ g8pelate\n   \"\n\npart_weakinv_fit &lt;- \n    cfa(part_weakinv_mod, data = data_star_selected_variables)\n\nsemPaths(part_weakinv_fit, what = \"col\")\n\n\n\n\n\n\n\nsemPaths(part_weakinv_fit, what = \"est\", fade = F)\n\n\n\n\n\n\n\nsummary(compareFit(part_configinv_fit, part_weakinv_fit))\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n                   Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\npart_configinv_fit 15 20737 20840 58.125                                       \npart_weakinv_fit   18 20739 20827 66.152     8.0274 0.040673       3    0.04545\n                    \npart_configinv_fit  \npart_weakinv_fit   *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n                     chisq df pvalue rmsea   cfi   tli  srmr        aic\npart_configinv_fit 58.125‚Ä† 15   .000 .053  .979‚Ä† .960  .029‚Ä† 20736.632‚Ä†\npart_weakinv_fit   66.152  18   .000 .051‚Ä† .976  .963‚Ä† .036  20738.660 \n                          bic\npart_configinv_fit 20839.966 \npart_weakinv_fit   20827.232‚Ä†\n\n################## Differences in Fit Indices #######################\n                                      df  rmsea    cfi   tli  srmr   aic\npart_weakinv_fit - part_configinv_fit  3 -0.002 -0.002 0.003 0.007 2.027\n                                          bic\npart_weakinv_fit - part_configinv_fit -12.735",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>L√§ngsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html#starke-invarianz",
    "href": "longitudinal_measurement_invariance.html#starke-invarianz",
    "title": "3¬† L√§ngsschnittliche Messinvarianz",
    "section": "3.3 Starke Invarianz",
    "text": "3.3 Starke Invarianz\n\npart_stronginv_mod &lt;- \n  \"part4e =~ g4ptattn + s1*g4ptmtrl + s2*g4ptpers + s3*g4ptlate \n   part8e =~ g8peattn + s1*g8pemtrl + s2*g8pepers + s3*g8pelate\n\n   # latent (co-)variances with constrains\n   part4e ~~ v1*part4e\n   part8e ~~ v1*part8e\n   part4e ~~ part8e\n   \n   # residual variances\n   g4ptattn ~~ g4ptattn\n   g4ptmtrl ~~ g4ptmtrl\n   g4ptpers ~~ g4ptpers\n   g4ptlate ~~ g4ptlate\n   g8peattn ~~ g8peattn\n   g8pemtrl ~~ g8pemtrl\n   g8pepers ~~ g8pepers\n   g8pelate ~~ g8pelate\n   \n   # set residual covariances free over time per indicator\n   g4ptattn ~~ g8peattn\n   g4ptmtrl ~~ g8pemtrl\n   g4ptpers ~~ g8pepers\n   g4ptlate ~~ g8pelate\n   \"\n\npart_stronginv_fit &lt;- \n    cfa(part_stronginv_mod, data = data_star_selected_variables)\n\nsemPaths(part_stronginv_fit, what = \"col\")\n\n\n\n\n\n\n\nsemPaths(part_stronginv_fit, what = \"est\", fade = F)\n\n\n\n\n\n\n\nsummary(compareFit(part_configinv_fit, part_weakinv_fit, part_stronginv_fit))\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n                   Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\npart_configinv_fit 15 20737 20840 58.125                                       \npart_weakinv_fit   18 20739 20827 66.152     8.0274 0.040673       3    0.04545\npart_stronginv_fit 19 20737 20820 66.373     0.2203 0.000000       1    0.63879\n                    \npart_configinv_fit  \npart_weakinv_fit   *\npart_stronginv_fit  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n                     chisq df pvalue rmsea   cfi   tli  srmr        aic\npart_configinv_fit 58.125‚Ä† 15   .000 .053  .979‚Ä† .960  .029‚Ä† 20736.632‚Ä†\npart_weakinv_fit   66.152  18   .000 .051  .976  .963  .036  20738.660 \npart_stronginv_fit 66.373  19   .000 .050‚Ä† .977  .966‚Ä† .036  20736.880 \n                          bic\npart_configinv_fit 20839.966 \npart_weakinv_fit   20827.232 \npart_stronginv_fit 20820.531‚Ä†\n\n################## Differences in Fit Indices #######################\n                                      df  rmsea    cfi   tli  srmr    aic\npart_weakinv_fit - part_configinv_fit  3 -0.002 -0.002 0.003 0.007  2.027\npart_stronginv_fit - part_weakinv_fit  1 -0.002  0.000 0.003 0.000 -1.780\n                                          bic\npart_weakinv_fit - part_configinv_fit -12.735\npart_stronginv_fit - part_weakinv_fit  -6.700",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>L√§ngsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html#strikte-invarianz",
    "href": "longitudinal_measurement_invariance.html#strikte-invarianz",
    "title": "3¬† L√§ngsschnittliche Messinvarianz",
    "section": "3.4 Strikte Invarianz",
    "text": "3.4 Strikte Invarianz\n\npart_strictinv_mod &lt;- \n  \"part4e =~ g4ptattn + s1*g4ptmtrl + s2*g4ptpers + s3*g4ptlate \n   part8e =~ g8peattn + s1*g8pemtrl + s2*g8pepers + s3*g8pelate\n\n   # latent (co-)variances with constrains\n   part4e ~~ v1*part4e\n   part8e ~~ v1*part8e\n   part4e ~~ part8e\n   \n   # residual variances\n   g4ptattn ~~ r1*g4ptattn\n   g4ptmtrl ~~ r2*g4ptmtrl\n   g4ptpers ~~ r3*g4ptpers\n   g4ptlate ~~ r4*g4ptlate\n   g8peattn ~~ r1*g8peattn\n   g8pemtrl ~~ r2*g8pemtrl\n   g8pepers ~~ r3*g8pepers\n   g8pelate ~~ r4*g8pelate\n   \n   # set residual covariances free over time per indicator\n   g4ptattn ~~ g8peattn\n   g4ptmtrl ~~ g8pemtrl\n   g4ptpers ~~ g8pepers\n   g4ptlate ~~ g8pelate\n   \"\n\npart_strictinv_fit &lt;- \n    cfa(part_strictinv_mod, data = data_star_selected_variables)\n\nsemPaths(part_strictinv_fit, what = \"col\")\n\n\n\n\n\n\n\nsemPaths(part_strictinv_fit, what = \"est\", fade = F)\n\n\n\n\n\n\n\nsummary(compareFit(part_configinv_fit, part_weakinv_fit, \n                   part_stronginv_fit, part_strictinv_fit))\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n                   Df   AIC   BIC   Chisq Chisq diff    RMSEA Df diff\npart_configinv_fit 15 20737 20840  58.125                            \npart_weakinv_fit   18 20739 20827  66.152      8.027 0.040673       3\npart_stronginv_fit 19 20737 20820  66.373      0.220 0.000000       1\npart_strictinv_fit 23 20776 20840 113.485     47.113 0.103150       4\n                   Pr(&gt;Chisq)    \npart_configinv_fit               \npart_weakinv_fit      0.04545 *  \npart_stronginv_fit    0.63879    \npart_strictinv_fit  1.445e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n                      chisq df pvalue rmsea   cfi   tli  srmr        aic\npart_configinv_fit  58.125‚Ä† 15   .000 .053  .979‚Ä† .960  .029‚Ä† 20736.632‚Ä†\npart_weakinv_fit    66.152  18   .000 .051  .976  .963  .036  20738.660 \npart_stronginv_fit  66.373  19   .000 .050‚Ä† .977  .966‚Ä† .036  20736.880 \npart_strictinv_fit 113.485  23   .000 .062  .955  .946  .049  20775.993 \n                          bic\npart_configinv_fit 20839.966 \npart_weakinv_fit   20827.232 \npart_stronginv_fit 20820.531‚Ä†\npart_strictinv_fit 20839.961 \n\n################## Differences in Fit Indices #######################\n                                        df  rmsea    cfi    tli  srmr    aic\npart_weakinv_fit - part_configinv_fit    3 -0.002 -0.002  0.003 0.007  2.027\npart_stronginv_fit - part_weakinv_fit    1 -0.002  0.000  0.003 0.000 -1.780\npart_strictinv_fit - part_stronginv_fit  4  0.013 -0.021 -0.020 0.013 39.113\n                                            bic\npart_weakinv_fit - part_configinv_fit   -12.735\npart_stronginv_fit - part_weakinv_fit    -6.700\npart_strictinv_fit - part_stronginv_fit  19.430",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>L√§ngsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html#weiterf√ºhrende-literatur",
    "href": "longitudinal_measurement_invariance.html#weiterf√ºhrende-literatur",
    "title": "3¬† L√§ngsschnittliche Messinvarianz",
    "section": "3.5 Weiterf√ºhrende Literatur",
    "text": "3.5 Weiterf√ºhrende Literatur\n\n\n\n\n\n\nLiteraturempfehlungen zum Thema Longitudinal Measurement Invariance\n\n\n\n\n\n\nMackinnon, S., Curtis, R., & O‚ÄôConnor, R. (2024). A Tutorial in Longitudinal Measurement Invariance and Cross-lagged Panel Models Using lavaan. https://doi.org/10.31234/osf.io/tkzrb\nBrown, T. A. (2015). Confirmatory factor analysis for applied research. Guilford Press.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>L√§ngsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "cross_lagged_panel_models.html",
    "href": "cross_lagged_panel_models.html",
    "title": "4¬† Cross Lagged Panel Modelle",
    "section": "",
    "text": "4.1 Weiterf√ºhrende Literatur",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Cross Lagged Panel Modelle</span>"
    ]
  },
  {
    "objectID": "cross_lagged_panel_models.html#weiterf√ºhrende-literatur",
    "href": "cross_lagged_panel_models.html#weiterf√ºhrende-literatur",
    "title": "4¬† Cross Lagged Panel Modelle",
    "section": "",
    "text": "Literaturempfehlungen zum Thema Cross Lagged Panel Models\n\n\n\n\n\n\nMackinnon, S., Curtis, R., & O‚ÄôConnor, R. (2024). A Tutorial in Longitudinal Measurement Invariance and Cross-lagged Panel Models Using lavaan. https://doi.org/10.31234/osf.io/tkzrb\nMcArdle, J. J., & Grimm, K. J. (2010). Five steps in latent curve and latent change score modeling with longitudinal data. In K. van Montfort, J. H. L. Oud, & A. Satorra (Hrsg.), Longitudinal Research with Latent Variables (S. 245‚Äì273). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-11760-2_8",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Cross Lagged Panel Modelle</span>"
    ]
  },
  {
    "objectID": "latent_change_score_models.html",
    "href": "latent_change_score_models.html",
    "title": "5¬† Latent Change Score Models",
    "section": "",
    "text": "library(lavaan)\n\nWarning: package 'lavaan' was built under R version 4.2.3\n\n\nThis is lavaan 0.6-17\nlavaan is FREE software! Please report any bugs.\n\nlibrary(haven)\n\nWarning: package 'haven' was built under R version 4.2.3\n\nlibrary(semPlot)\n\n# read complete data\ndata_star &lt;- read_spss(\"data/STAR_Students.sav\")\n\nFailed to find G1READ_A\nFailed to find G1MATH_A\nFailed to find G2READ_A\nFailed to find G2MATH_A\nFailed to find G3READ_A\nFailed to find G3MATH_A\n\n# read selected variables\ndata_star_selected_variables &lt;- \n    read_spss(\"data/data_star_selected_variables.sav\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Latent Change Score Models</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Achilles, C. M., Helen Pate Bain, F. Bellot, J. Boyd-Zaharias, J. Finn,\nJ. Folger, John Johnston, and Elizabeth Word. 1985. ‚ÄúThe State of\nTennessee‚Äôs Student/Teacher Achievement Ratio\n(STAR) Project.‚Äù Technical {{Report}}.\nTennessee State Department of Educatbn.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. 2nd ed. New Jersey: Lawrence\nErlbaum.\n\n\nDennis, Ian. 2007. ‚ÄúHalo Effects in Grading Student\nProjects.‚Äù Journal of Applied Psychology 92 (4):\n1169‚Äì76. https://doi.org/10.1037/0021-9010.92.4.1169.\n\n\nD√∂ring, Nicola, and J√ºrgen Bortz. 2016. Forschungsmethoden und\nEvaluation in den Sozial- und Humanwissenschaften. 5.,\nvollst. Berlin, Heidelberg: Springer.\n\n\nMoosbrugger, Helfried. 2011. Lineare Modelle: Regressions- und\nVarianzanalysen ; mit einem Anhang √ºber\nMatrixalgebra. 4., vollst√§ndig\n√ºberarbeitete und erg√§nzte Auflage.\nPsychologie Lehrtexte. Bern: Verlag Hans\nHuber.",
    "crumbs": [
      "Literatur"
    ]
  },
  {
    "objectID": "grundlegende_ideen.html",
    "href": "grundlegende_ideen.html",
    "title": "1¬† Grundlegende Ideen Bayesianischer Datenanalyse",
    "section": "",
    "text": "1.1 Wahrscheinlichkeitsbegriff von Laplace\nDie mathematische Wahrscheinlichkeitstheorie (Stochastik) ist ein vergleichsweise junge Subdisziplin, die erst zu Beginn des 20. Jahrhunderts axiomatisch formalisiert wurde. in diesen Ans√§tzen definiert man Wahrscheinlichkeitsma√üe z.B. durch die folgenden Axiome.\nDas ist weder besonders intuitiv noch hilfreich f√ºr die Anwendung in der Datenanalyse. Eine wichtige Kontextinfromation k√∂nnte jedoch sein, dass die Wahrscheinlichkeitsrechnung bis ins 19. Jhd. hinein vor allem als Hilfsmittel f√ºr Gl√ºcksspiele und Wetten entwickelt wurde. In diesem Kontext ist es recht hilfreich und intuitiv Wahrscheinlichkeit als relative H√§ufigkeit zu verstehen. So findet man auch etwa in Mathematikb√ºchern der 7.ten Klasse Aussagen wie",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Ideen Bayesianischer Datenanalyse</span>"
    ]
  },
  {
    "objectID": "grundlegende_ideen.html#wahrscheinlichkeitsbegriff",
    "href": "grundlegende_ideen.html#wahrscheinlichkeitsbegriff",
    "title": "1¬† Grundlegende Ideen Bayesianischer Datenanalyse",
    "section": "",
    "text": "‚ÄúDie Wahrscheinlichkeit, dass eine gerade Zahl gew√ºrfelt wird, betr√§gt 3/6, denn es gibt 6 m√∂gliche Ergebnisse und drei g√ºnstige.‚Äù",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Ideen Bayesianischer Datenanalyse</span>"
    ]
  },
  {
    "objectID": "grundlegende_ideen.html#stochastik-vs.-statistik",
    "href": "grundlegende_ideen.html#stochastik-vs.-statistik",
    "title": "1¬† Grundlegende Ideen Bayesianischer Datenanalyse",
    "section": "1.2 Stochastik vs.¬†Statistik",
    "text": "1.2 Stochastik vs.¬†Statistik\nInfolge dessen waren dann viele Mathematiker:innen daran interessiert bei welchen Spielen mit welche Strategien mit welcher Wahrscheinlichkeit welcher Erfolg eintritt. Also zum Beispiel beim Roulette: Ich starte mit 10.000‚Ç¨ und setze immer 100‚Ç¨ + die Gewinne aus den Vorrunden auf Rot. Wie wahrscheinlich ist es, dass ich in 100 Runden 20.000‚Ç¨ habe? Wie wahrscheinlich ist es, dass ich nach 100 Runden pleite bin? Die Berechnung der Wahrscheinlichkeit solcher real einretender Szenarien (= Daten) kann man anstellen, weil man die Wahrscheinlichekit der Elementarereignisse (Rot, Schwarz, Gr√ºn) kennt. Das ist das kerninteresse der Stochastik.\nDie Statistik hingegen interessiert sich f√ºr die umgekehrte Frage: Wenn ich die Beobachtungen (Daten) habe, was kann ich dann √ºber die Wahrscheinlichkeiten der Elementarereignisse sagen?",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Ideen Bayesianischer Datenanalyse</span>"
    ]
  },
  {
    "objectID": "grundlegende_ideen.html#bayes-theorem",
    "href": "grundlegende_ideen.html#bayes-theorem",
    "title": "1¬† Grundlegende Ideen Bayesianischer Datenanalyse",
    "section": "1.4 Bayes Theorem",
    "text": "1.4 Bayes Theorem\nBayes Theorem ist ein stochastischer Satz der eine bedingte Wahrscheinlichkeit \\(P(A|B)\\) zur bedingten Wahrscheinlichkeit \\(P(B|A)\\) in die andere Richtung umrechnet.\n\\(P(A|B)\\) ist dabei schulmathematisch als ¬ªDie Wahrscheinlichkeit dass A eintritt unter der Annahme, dass B bereits eingetreten ist¬´ zu verstehen.\n\nBeispiel: Es liegen in einer Urne 2 blaue und vier gr√ºne Kugeln, ich ziehe zwei Kugeln ohne zur√ºcklegen.\nIst das Ereignis \\(A\\) = ¬ªBlaue Kugel im ersten Zug¬´, \\(B\\) = ¬ªgr√ºne Kugel im ersten Zug¬´ und \\(C\\) = ¬ªgr√ºne Kugel im zweiten Zug¬´ dann ist \\(P(C|A) = 4/5\\) und \\(P(C|B) = 3/5\\)\n\n\n1.4.1 Dynamische Veranschaulichung\nDie beste dynamische Visualisierung zur Erkl√§rung des Bayes Theorems, die ich kenne, ist die folgende:\n\nGefragt wird ja zu Beginn nach \\(P(Librarian|meek\\;and\\;tidy\\;soul)\\) welche unter Verwendung der Wahrscheinlichkeit \\(P(meek\\;and\\;tidy\\;soul|Librarian)\\) berechnet wird.\nVerallgemeinert kann man sagen dass Bayes Theorem die Wahrscheinlichkeit \\(P(Hypothesis|Data)\\) unter Verwendung der Wahrscheinlichkeit \\(P(Data|Hypothesis)\\) mit folgender Formel berechnet:\n\\[\n{\\color{grey} \\overbracket[0.25pt]{\\color{bayesorange} P (\\text{Unknown} \\mid \\text{Data})}^{\\text{Posterior}}} = \\frac\n{{\\color{grey} \\overbracket[0.25pt]{\\color{bayesred} P (\\text{Unknown})}^{\\text{Prior}}} \\times\n{\\color{grey} \\overbracket[0.25pt]{\\color{bayesblue} P (\\text{Data} \\mid \\text{Unknown})}^{\\text{Likelihood}}}}\n{{\\color{grey} \\underbracket[0.25pt]{{\\color{grey} P(\\text{E})}}_{\\text{Average likelihood}}}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Ideen Bayesianischer Datenanalyse</span>"
    ]
  },
  {
    "objectID": "grundlegende_ideen.html#wahrscheinlichkeitsbegriff-von-laplace",
    "href": "grundlegende_ideen.html#wahrscheinlichkeitsbegriff-von-laplace",
    "title": "1¬† Grundlegende Ideen Bayesianischer Datenanalyse",
    "section": "",
    "text": "‚ÄúDie Wahrscheinlichkeit, dass eine gerade Zahl gew√ºrfelt wird, betr√§gt 3/6, denn es gibt 6 m√∂gliche Ergebnisse und drei g√ºnstige.‚Äù",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Ideen Bayesianischer Datenanalyse</span>"
    ]
  },
  {
    "objectID": "grundlegende_ideen.html#bayesianischer-wahrscheinlichkeitsbegriff",
    "href": "grundlegende_ideen.html#bayesianischer-wahrscheinlichkeitsbegriff",
    "title": "1¬† Grundlegende Ideen Bayesianischer Datenanalyse",
    "section": "1.3 Bayesianischer Wahrscheinlichkeitsbegriff",
    "text": "1.3 Bayesianischer Wahrscheinlichkeitsbegriff\nWenn es sich bei den Elementarereignissen nicht um Gl√ºcksspiele handelt, kann die relative H√§ufigkeit etwas kontraintuitiv sein: Wenn die Wahrscheinlichkeit einer Befragung ergibt, dass Donald J. Trump üçä mit 54% Wahrscheinlichkeit eine neue Amtszeit bekommt, dann ist die Interpretation, dass er in 54 von 100 F√§llen gewinnt nicht besonders hilfreich. Vielmehr ist die Wahrscheinlichkeit dann eine Aussage √ºber die Unsicherheit, die wir haben, wenn wir aufgrund der Daten Schlussfolgerungen √ºber den die Daten generierenden Mechanismus treffen wollen. Die 54% w√ºrden dann also als ¬ªziemlich genau in der Mitte von unm√∂glich und sicher¬´ interpretiert werden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Ideen Bayesianischer Datenanalyse</span>"
    ]
  },
  {
    "objectID": "highest_density_intervals.html",
    "href": "highest_density_intervals.html",
    "title": "3¬† Highest Density Intervals (HDI)",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 800\n\nlibrary(bslib)\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Prior\"),\n         card_body(\n           sliderInput(\n             \"prior_mu\",\n             \"Prior Mean\",\n             min = 0,\n             max = 1,\n             value = .5,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi\",\n             \"Prior Precision\",\n             min = 2,\n             max = 100,\n             value = 3,\n             step = 1\n           )\n         )),\n    card(card_header(class = \"bg-dark\", \"Data\"),\n         card_body(\n           numericInput(\n             \"successes\",\n             \"n‚ÇÅ = Zustimmung G9\",\n             min = 0,\n             value = 13,\n             step = 1\n           ),\n           numericInput(\n             \"failures\",\n             \"n‚ÇÇ = Ablehnung G9\",\n             min = 0,\n             value = 8,\n             step = 1\n           )\n         ))), \n  card(card_header(\"Posterior\", class = \"bg-dark\"),\n       card_body(plotOutput(\"plot\")))\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n### custom functions ###########################################################\n# muphi_to_shapes \nmuphi_to_shapes &lt;- function(mu, phi) {\n  shape1 &lt;- mu * phi\n  shape2 &lt;- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n### aux variables ##############################################################\n# convert prior parameterization\n\nprior_shapes &lt;- reactive({\n  muphi_to_shapes(input$prior_mu, input$prior_phi)\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n  \n  # set x-axis\n  p &lt;- seq(0,1, length=1000)\n  \n  # compute max-desity for ylim and legend position\n  density_max &lt;-\n    max(c(\n      dbeta(p,\n            prior_shapes()$shape1,\n            prior_shapes()$shape2),\n      dbeta(\n        p,\n        prior_shapes()$shape1 + input$successes,\n        prior_shapes()$shape2 + input$failures\n      )\n    ))\n  \n  # compute lower bound of 96%-HPDI\n  hpdi_lb &lt;-\n    qbeta(.02,\n           prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  # compute upper bound of 96%-HPDI\n  hpdi_ub &lt;-\n    qbeta(.98,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  \n  # create plot\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes()$shape1,\n          prior_shapes()$shape2),\n    type = 'l',\n    col = \"#1bbc9d\",\n    ylab = \"Wahrscheinlichkeitsdichte\",\n    xlab = \"Anteil G9-Bef√ºrworter:innen\",\n    frame.plot = F,\n    ylim = c(0, density_max)\n    )\n  lines(p,\n        dbeta(\n          p,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures\n          ),\n          col = '#EA80FC'\n        )\n  polygon(c(hpdi_lb, hpdi_lb, hpdi_ub, hpdi_ub),\n          c(0, density_max/40, density_max/40, 0),\n          col = \"#EA80FC30\",\n          border = \"#EA80FC00\")\n  legend(\n    bty = \"n\",\n    .8,\n    density_max,\n    c('Prior', 'Posterior', '96% HPDI'),\n    lty = c(1, 1, 1),\n    lwd = c(1, 1, 8),\n    col = c('#1bbc9d', '#EA80FC', '#EA80FC30')\n  )\n\n})\n\n### debug ######################################################################\n# output$debug &lt;- renderPrint({\n#   max(c(\n#                dbeta(p, \n#                      prior_shapes()$shape1, \n#                      prior_shapes()$shape2),\n#                dbeta(p, \n#                      prior_shapes()$shape1 + input$successes, \n#                      prior_shapes()$shape2 + input$failures))\n#              )\n#              \n# })\n\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Highest Density Intervals (HDI)</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html",
    "href": "grundlegende_begriffe.html",
    "title": "1¬† Grundlegende Begriffe",
    "section": "",
    "text": "1.1 Wahrscheinlichkeitsbegriff von Laplace\nDie mathematische Wahrscheinlichkeitstheorie (Stochastik) ist ein vergleichsweise junge Subdisziplin, die erst zu Beginn des 20. Jahrhunderts axiomatisch formalisiert wurde. in diesen Ans√§tzen definiert man Wahrscheinlichkeitsma√üe z.B. durch die folgenden Axiome.\nDas ist weder besonders intuitiv noch hilfreich f√ºr die Anwendung in der Datenanalyse. Eine wichtige Kontextinfromation k√∂nnte jedoch sein, dass die Wahrscheinlichkeitsrechnung bis ins 19. Jhd. hinein vor allem als Hilfsmittel f√ºr Gl√ºcksspiele und Wetten entwickelt wurde. In diesem Kontext ist es recht hilfreich und intuitiv Wahrscheinlichkeit als relative H√§ufigkeit zu verstehen. So findet man auch etwa in Mathematikb√ºchern der 7.ten Klasse Aussagen wie",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#wahrscheinlichkeitsbegriff-von-laplace",
    "href": "grundlegende_begriffe.html#wahrscheinlichkeitsbegriff-von-laplace",
    "title": "1¬† Grundlegende Begriffe",
    "section": "",
    "text": "‚ÄúDie Wahrscheinlichkeit, dass eine gerade Zahl gew√ºrfelt wird, betr√§gt 3/6, denn es gibt 6 m√∂gliche Ergebnisse und drei g√ºnstige.‚Äù",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#stochastik-vs.-statistik",
    "href": "grundlegende_begriffe.html#stochastik-vs.-statistik",
    "title": "1¬† Grundlegende Begriffe",
    "section": "1.2 Stochastik vs.¬†Statistik",
    "text": "1.2 Stochastik vs.¬†Statistik\nInfolge dessen waren dann viele Mathematiker:innen daran interessiert bei welchen Spielen mit welche Strategien mit welcher Wahrscheinlichkeit welcher Erfolg eintritt. Also zum Beispiel beim Roulette: Ich starte mit 10.000‚Ç¨ und setze immer 100‚Ç¨ + die Gewinne aus den Vorrunden auf Rot. Wie wahrscheinlich ist es, dass ich in 100 Runden 20.000‚Ç¨ habe? Wie wahrscheinlich ist es, dass ich nach 100 Runden pleite bin? Die Berechnung der Wahrscheinlichkeit solcher real einretender Szenarien (= Daten) kann man anstellen, weil man die Wahrscheinlichekit der Elementarereignisse (Rot, Schwarz, Gr√ºn) kennt. Das ist das kerninteresse der Stochastik.\nDie Statistik hingegen interessiert sich f√ºr die umgekehrte Frage: Wenn ich die Beobachtungen (Daten) habe, was kann ich dann √ºber die Wahrscheinlichkeiten der Elementarereignisse sagen?",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#bayesianischer-wahrscheinlichkeitsbegriff",
    "href": "grundlegende_begriffe.html#bayesianischer-wahrscheinlichkeitsbegriff",
    "title": "1¬† Grundlegende Begriffe",
    "section": "1.3 Bayesianischer Wahrscheinlichkeitsbegriff",
    "text": "1.3 Bayesianischer Wahrscheinlichkeitsbegriff\nWenn es sich bei den Elementarereignissen nicht um Gl√ºcksspiele handelt, kann die relative H√§ufigkeit etwas kontraintuitiv sein: Wenn die Wahrscheinlichkeit einer Befragung ergibt, dass Donald J. Trump üçä mit 54% Wahrscheinlichkeit eine neue Amtszeit bekommt, dann ist die Interpretation, dass er in 54 von 100 F√§llen gewinnt nicht besonders hilfreich. Vielmehr ist die Wahrscheinlichkeit dann eine Aussage √ºber die Unsicherheit, die wir haben, wenn wir aufgrund der Daten Schlussfolgerungen √ºber den die Daten generierenden Mechanismus treffen wollen. Die 54% w√ºrden dann also als ¬ªziemlich genau in der Mitte von unm√∂glich und sicher¬´ interpretiert werden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "grundlegende_begriffe.html#bayes-theorem",
    "href": "grundlegende_begriffe.html#bayes-theorem",
    "title": "1¬† Grundlegende Begriffe",
    "section": "1.4 Bayes Theorem",
    "text": "1.4 Bayes Theorem\nBayes Theorem ist ein stochastischer Satz der eine bedingte Wahrscheinlichkeit \\(P(A|B)\\) zur bedingten Wahrscheinlichkeit \\(P(B|A)\\) in die andere Richtung umrechnet.\n\\(P(A|B)\\) ist dabei schulmathematisch als ¬ªDie Wahrscheinlichkeit dass A eintritt unter der Annahme, dass B bereits eingetreten ist¬´ zu verstehen.\n\nBeispiel: Es liegen in einer Urne 2 blaue und vier gr√ºne Kugeln, ich ziehe zwei Kugeln ohne zur√ºcklegen.\nIst das Ereignis \\(A\\) = ¬ªBlaue Kugel im ersten Zug¬´, \\(B\\) = ¬ªgr√ºne Kugel im ersten Zug¬´ und \\(C\\) = ¬ªgr√ºne Kugel im zweiten Zug¬´ dann ist \\(P(C|A) = 4/5\\) und \\(P(C|B) = 3/5\\)\n\n\n1.4.1 Dynamische Veranschaulichung\nDie beste dynamische Visualisierung zur Erkl√§rung des Bayes Theorems, die ich kenne, ist die folgende:\n\nGefragt wird ja zu Beginn nach \\(P(\\text{librarian}|\\text{meek\\;and\\;tidy\\;soul})\\) welche unter Verwendung der Wahrscheinlichkeit \\(P(\\text{meek\\;and\\;tidy\\;soul}|\\text{librarian})\\) berechnet wird.\nVerallgemeinert kann man sagen dass Bayes Theorem die Wahrscheinlichkeit \\(P(\\text{Hypothesis}|\\text{Data})\\) unter Verwendung der Wahrscheinlichkeit \\(P(\\text{Data}|\\text{Hypothesis})\\) mit folgender Formel berechnet:\n\\[\n{\\overbracket[0.25pt]{P (\\text{Hypothesis} \\mid \\text{Data})}^{\\text{Posterior}}} = \\frac\n{{\\overbracket[0.25pt]{P (\\text{Hypothesis})}^{\\text{Prior}}} \\times\n{\\overbracket[0.25pt]{P (\\text{Data} \\mid \\text{Hypothesis})}^{\\text{Likelihood}}}}\n{{\\underbracket[0.25pt]{{P(\\text{E})}}_{\\text{Average likelihood}}}}\n\\]\nIm YouTube-Beispiel haben wir gesehen wie Bayes Theorem auf ein Modell angewendet wird, das wir uns als Urne mit Kugeln zweier Farben vorstellen k√∂nnen, wobei eine Farbe Farmer und eien Farbe Librarians enkodiert.\nIn der Regressionsmodellierung wird Bayes Theorem benutzt um die Parameter eines Regressionsmodells zu spezifizieren. Nehmen wir an wir wollen modellieren mit welcher Vorbereitungszeit welcher Erfolg in einer Klausur einhergeht, k√∂nnten Prior (Predictions), Data & Likelihood sowie Posterior (Predictions) wie folgt aussehen:\n Bevor wir uns aber anschauen wie wir zu diesen Posterior-Verteilungen kommen, schauen wir uns nochmal die grundlegende Unterscheidung Inferenz- und Deskriptivstatistik sowie zwischen Sch√§tzung und Testung an.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Grundlegende Begriffe</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "",
    "text": "2.1 Inferenz- und Deskriptivstatistik",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#inferenz--und-deskriptivstatistik",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#inferenz--und-deskriptivstatistik",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "",
    "text": "Deskriptivstatistiken machen Aussagen √ºber vorliegende Datens√§tze z.B. ¬ªMedian aller Noten eines Zeugnisses¬´\n\n\n\nInferenzstatistiken machen anhand von Daten Aussagen √ºber (hypothetische) Mechanismen, die diese Daten erzeugen (Eid, Gollwitzer, & Schmitt, 2013) z.B. ¬ªBef√ºrworten von 100 zuf√§llig ausgew√§hlten Erwachsenen 63 Ziffernnoten in der Grundschule, wie sicher liegt dann eine Zustimmung (&gt; 50%) in der Gesamterwachsenenbev√∂lkerung vor?¬´",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#sch√§tzung-vs.-testung",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#sch√§tzung-vs.-testung",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "2.2 Sch√§tzung vs.¬†Testung",
    "text": "2.2 Sch√§tzung vs.¬†Testung\n\n\n\n\n\n\n\n\n\nFrequentistischeStatistik\nBayesianischeStatistik\n\n\n\n\nParametersch√§tzung\nKonfidenzintervalle\nPosterior Distributions\n\n\nHypothesentest\np-Werte\nBayes Faktoren/ROPE +HDI.\n\n\n\n\nInferenzstatistische Sch√§tzung (estimation with quantified uncertainty) trifft anhand von Stichproben Aussagen √ºber Parameter der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.  (Inferenzstatistische) Hypothesentests bewerten anhand von Stichprobendaten die G√ºltigkeit von Hypothesen in der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde (Kruschke & Liddell, 2018).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#hypothesenarten",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#hypothesenarten",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "2.3 Hypothesenarten",
    "text": "2.3 Hypothesenarten\nBayesianische wie frequentistischen Hypothesentests k√∂nnen unterschiedliche Arten von Hypothesen zugrunde gelegt werden:\n\nPunkthypothesen setzen Parameter gleich einer reellen Zahl; etwa \\(H_0\\text{: } \\delta = 0\\)\n√Ñquivalenzhypothesen nehmen Parameter in einem reellen Intervall an; etwa \\(H_0\\text{: } \\delta \\not\\in\\ [-.3, .3]\\)\nInformative Hypothesen nehmen eine Ordnungsrelation mehrerer Parameter an; etwa \\(\\mu_{\\text{Baseline}} &lt; \\mu_{\\text{Imaginary Pill}} &lt; \\mu_{\\text{Blinded Placebo}}\\) (Buergler u.¬†a., 2023)\n\n\nDie Art der (falsifizierten) Hypothese entscheidet wesentlich st√§rker √ºber den Informationsgehalt eines Hypothesentests als die Entscheidung f√ºr das frequentistische oder bayesianische Paradigma (Hoijtink, 2012).\n\nDies ist am leichtest anhand der Nullhypothese nachvollziehbar. Wird etwa die Nullhypothese \\(H_0\\text{: } \\delta = 0\\) verworfen, wird entsprechend die Alternativhypothese \\(H_A\\text{: } \\delta \\neq 0\\) angenommen. Diese enth√§lt aber quasi keine Information, da sie nur mit einer einzigen Beobachtung (d = 0.000000 ‚Ä¶) verworfen werden kann und im kritischen Rationalismus gilt, dass eine Aussage umso mehr Information enth√§lt, umso leichter sie verworfen werden kann (D√∂ring & Bortz, 2016).\n√Ñquivalenzhypothesen k√∂nnen sowohl frequentistisch (z.B. TOAST-Prozedur in  und JASP, Lakens, 2017) wie bayesianisch (z.B. ROPE-Ansatz Kruschke, 2015) getestet werden. F√ºr das Testen informativer Hypothesen liegen bayesianische Methoden in (u.a.) JASP und  vor (z.B. {bain}, Gu, Hoijtink, Mulder, & Rosseel, 2019).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-f√ºr-punkthypothesen",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-f√ºr-punkthypothesen",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "2.4 Bayes Faktoren f√ºr Punkthypothesen",
    "text": "2.4 Bayes Faktoren f√ºr Punkthypothesen\n\n2.4.1 Definition und deren Plausibilisierung\nDer Bayes Faktor ist wie folgt definiert:\n\\[\nBF=\\frac{P\\left(D \\mid H_1\\right)}{P\\left(D\\mid H_2\\right)}\n\\] Wobei \\(D\\) f√ºr ¬ªData¬´ steht und \\(H_1\\) und \\(H_2\\) f√ºr Modell 1 und Modell 2 stehen - oftmals wird stattdessen auch Hypothese 1 \\(H_1\\) und Hypothese 2 \\(H_2\\) geschrieben, was dasselbe meint.\nDass der BF relative Evidenz quantifiziert, wird bereits aus der Definition klar, verbreitete Fehlverst√§ndnisse (Tendeiro, Kiers, Hoekstra, Wong, & Morey, 2024) werden hoffentlich einged√§mmt, wenn man sich klar macht, dass aus dieser Definition mithilfe des Bayes Theorem folgt\n\\[\nBF=\\frac{P\\left(D \\mid H_1\\right)}{P\\left(D\\mid H_2\\right)}\\overset{\\text{Bayes Theorem}}{=}\\frac{\\frac{P\\left(D \\mid H_1\\right) \\cdot P(D)}{P\\left(H_1\\right)}}{\\frac{P\\left(D \\mid H_2\\right) \\cdot P(D)}{P\\left(H_2\\right)}}\\overset{\\text{K√ºrze } P(D)}{=}\\frac{P\\left(H_1 \\mid D\\right) \\cdot P\\left(H_2\\right)}{P\\left(H_2 \\mid D\\right) \\cdot P\\left(H_1\\right)} = \\frac{P\\left(H_1 \\mid D\\right)}{P\\left(H_2 \\mid D\\right)} \\cdot \\frac{P\\left(H_2\\right)}{P\\left(H_1\\right)}\n\\]\nStellt man nun die Gleichung um erh√§lt man:\n\\[\n\\frac{P\\left(H_1 \\mid D\\right)}{P\\left(H_2 \\mid D\\right)} = \\frac{P\\left(H_1\\right)}{P\\left(H_2\\right)} \\cdot \\frac{P\\left(D \\mid H_1\\right)}{P\\left(D\\mid H_2\\right)}\n\\]\nalso\n\\[\n\\text{Posterior Odds} = \\text{Prior Odds} \\cdot \\text{Bayes Faktor}\n\\]\nDer Bayes Faktor ist also der Multiplikator (Faktor), der die Prior Odds in die Posterior Odds transformiert (updatet).\n\n\n2.4.2 Berechnung & Interpretation im Minimalbeispiel\n\nAufgabe L√∂sungshilfeMeine Rechnung\n\n\nAngenommen zwei Bildungspolitiker:innen streiten sich √ºber die Verbreitung der Elternmeinung zur Bef√ºrwortung von G8 vs.¬†G9. Die eine Politikerin behauptet, dass 45% der Eltern G9 bef√ºrworten, die andere Politikerin behauptet, dass 58% der Eltern G9 bef√ºrworten. In einer ¬ªStudie¬´ wurden 4 Proband:innen befragt und genau drei davon waren pro G9 waren. Wie gro√ü ist der Bayes Faktor?\n\n\n\n\n\n\nIm ¬ªB√§umchen¬´ gilt laut Achtklassmathematik: Wahrscheinlichkeiten entlang eines Pfades multiplizieren, Wahrscheinlichkeiten entlang verschiedener Pfade addieren.\n\n\\(\\frac{P(\\text{drei aus 4 pro G9}|\\theta = .45) = 4\\cdot(.45 \\cdot .45 \\cdot .45 \\cdot .55)}{P(\\text{drei aus 4 pro G9}|\\theta = .58) = 4\\cdot(.58 \\cdot .58 \\cdot .58 \\cdot .42)} \\approx `{r} round((4*.45^3*.55)/(4*.58^3*.42), 3)`\\)\n\n\n\n\n\n2.4.3 Interaktive Visualisierung\nIm Beispiel zuvor, lagen Punkthypothesen vor. F√ºr diese ist die Berechnung des Bayes Faktors besonders einfach, da die Wahrscheinlichkeiten der Daten unter den Hypothesen direkt berechnet werden k√∂nnen.\n\n\n2.4.4 Interaktive Visualisierung\nIn dieser interaktiven Visualisierung kann man beobachten wie sich der Bayes Faktor in Abh√§ngigkeit von den Daten und den Hypothesen verh√§lt.\n\n\n\n\n\n\nAufgabe \n\n\n\n\n\nMacht euch mit der Bedienung der App vertraut und macht dann Vorhersagen √ºber die Ver√§nderung des Bayesfaktors, wenn sich die Daten oder Hypothesen √§ndern.\n\n\n\n#| standalone: true\n#| viewerHeight: 800\n\nlibrary(bslib)\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(shinyjs)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n   \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Punkthypothesen\"),\n         card_body(\n           sliderInput(\n               \"theta1\", \"Hypothese 1: Anteil Pro G9\",\n               min = 0,\n               max = 1,\n               value = .4,\n               step = .1\n           ),\n           sliderInput(\n               \"theta2\", \"Hypothese 2: Anteil Pro G8\",\n               min = 0,\n               max = 1,\n               value = .6,\n               step = .1\n           ))),\n    card(card_header(class = \"bg-dark\", \"Daten\"),\n         card_body(\n            numericInput(\n              \"prog9\",\n              \"n‚ÇÅ = Bef√ºrwortung G9\",\n              min = 0,\n              value = 10,\n              step = 1),\n           numericInput(\n             \"prog8\",\n             \"n‚ÇÇ = Bef√ºrwortung G8\",\n             min = 0,\n             value = 5,\n             step = 1)\n         ))), \n  card(card_header(\"Likelihoods und Bayes Factor\", class = \"bg-dark\"),\n       card_body(shinycssloaders::withSpinner(plotOutput(\"plot\"), color = \"#1bbc9d\")\n))\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n    \n# n &lt;- 30 # N()\n# obs &lt;- 20 input$prog9\n# theta1 &lt;- .5 # input$theta1\n# theta2 &lt;- .7 # input$theta2\n# wkeit1 &lt;- choose(n, obs)*theta1^obs*(1-theta1)^(n-obs) # wkeit1()\n# wkeit2 &lt;- choose(n, obs)*theta2^obs*(1-theta2)^(n-obs) # wkeit2()\n\n### custom reactive values #####################################################\nN &lt;- reactive({input$prog8 + input$prog9})\n\nwkeit1 &lt;- \n    reactive({choose(N(), \n                     input$prog9)*input$theta1^input$prog9*\n                  (1-input$theta1)^(N()-input$prog9)})\n\nwkeit2 &lt;- \n    reactive({choose(N(), \n                     input$prog9)*input$theta2^input$prog9*\n                  (1-input$theta2)^(N()-input$prog9)})\n\n### create data ################################################################\ndata &lt;- reactive({\n    return(\n        rbind(tibble(k = 1:N(),\n                     p = choose(N(), k)*input$theta1^k*(1-input$theta1)^(N()-k), \n                     theta = as.character(input$theta1)),\n              tibble(k = 1:N(),\n                     p = choose(N(), k)*input$theta2^k*(1-input$theta2)^(N()-k),  \n                     theta = as.character(input$theta2))) %&gt;% \n              mutate(obs_eq_k = k == N()) %&gt;% \n              as_tibble()\n    )\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n\n ggplot() +\n    # add whole binomial distributions with alpha\n    geom_segment(data = data() %&gt;% \n                          filter(theta == input$theta1), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p), \n                 color = \"#bc991b60\") +\n    geom_segment(data = data() %&gt;% \n                     filter(theta == input$theta2), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p), \n                 color = \"#bc1b9a50\") +\n    # add selected binomial distributions without alpha\n    geom_segment(data = data() %&gt;% \n                     filter(theta == input$theta1 & k == input$prog9), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p, color = \"#bc991b\")) +\n    geom_segment(data = data() %&gt;% \n                     filter(theta == input$theta2 & k == input$prog9), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p, color = \"#bc1b9a\")) +\n    theme_minimal() +\n    geom_text(data = tibble(x = input$prog9, y = -.005, \n                            text = paste(\"BF =\", \n                                         formatC(wkeit1()/wkeit2(), \n                                                 format = \"e\", \n                                                 digits = 2))),\n              aes(x, y, label = text)) +\n    xlab(\"Anzahl\") + ylab(\"Wahrscheinlichkeit\") +\n    ggtitle(\"Berechnung des Bayes-Faktors\", \"bei Punkthypothesen\") +\n    scale_color_identity(name = \"Likelihood\",\n                         breaks = c(\"#bc991b\", \"#bc1b9a\"),\n                         labels = c(\"Hyp. 1\", \"Hyp 2.\"),\n                         guide = \"legend\")\n})\n\n### debug ######################################################################\noutput$debug &lt;- renderPrint({\n data()\n})\n\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-f√ºr-verteilungshypothesen",
    "href": "hypothesen_testen_vs_parameter_schaetzen.html#bayes-faktoren-f√ºr-verteilungshypothesen",
    "title": "2¬† Hypothesen testen vs.¬†Parameter sch√§tzen",
    "section": "2.5 Bayes Faktoren f√ºr Verteilungshypothesen",
    "text": "2.5 Bayes Faktoren f√ºr Verteilungshypothesen\nPunkthypothesen sind in den meisten sozialwissenschaftlichen Anwendungen sehr wenig informativ. In der Regel sind die Hypothesen Verteilungshypothesen. Im G8- vs.¬†G9-Beispiel w√§re eine Verteilungshypothese etwa ¬ªBef√ºrwortung von G9 in der Bev√∂lkerung liegt recht sicher zwischen 35% und 45%¬´ oder ¬ªJeder Prozentsatz der G9-Bef√ºrwortung ist gleich wahrscheinlich¬´.\nSo informativ solche Hypothesen sind, erschweren sie die Berechnung des Bayes Faktors: Im Beispiel oben hatten wir das genaue \\(\\theta\\) und konnten anhand dessen mithilfe des B√§umchen die Wahrscheinlichkeiten der Daten unter den Hypothesen berechnen. Bei Verteilungshypothesen ist das nicht mehr m√∂glich, da diese Hypothesen unendlich viele \\(\\theta\\)s enthalten. Es wird daher √ºber die \\(\\theta\\)s marginalisiert:\n\\[P\\left(D \\mid H\\right)=\\int P(D \\mid \\theta) \\cdot \\pi(\\theta) d \\theta\\] Dies kann man sich vorstellen als eine Berechnung der Likelihood \\(P\\left(D \\mid \\theta\\right)\\) f√ºr jedes \\(\\theta\\) woraus dann ein um \\(\\pi(\\theta)\\) gewichteter Durchschnitt gebildet wird.\n\n2.5.1 Interaktive Visualisierung\n\n\n\n\n\n\nAufgabe \n\n\n\n\n\nMacht euch mit der Bedienung der App vertraut. Wie √§ndern sich die Marginal Likelihoods wenn die Hypothesen weniger pr√§zise werden? Wie √§ndert sich dadurch der Bayes Faktor? Ist das im EInklang mit der Idee von Occam‚Äôs Razor?\n\n\n\n#| standalone: true\n#| viewerHeight: 850\n\nlibrary(bslib)\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(shinyjs)\nlibrary(bayesplay)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n   \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Hypothese 1\"),\n      layout_column_wrap(\n         card(\n           sliderInput(\n             \"prior_mu1\",\n             \"Mittelwert Hypothese 1\",\n             min = 0,\n             max = 1,\n             value = .42,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi1\",\n             \"Pr√§zision Hypothese 1\",\n             min = 2,\n             max = 100,\n             value = 13,\n             step = 1\n           )),\n         card(\n           plotOutput(\"prior1\", height = \"200px\")\n         )\n         )),\n   \n    card(card_header(class = \"bg-dark\", \"Hypothese 2\"),\n      layout_column_wrap(\n         card(\n          sliderInput(\n             \"prior_mu2\",\n             \"Mittelwert Hypothese 2\",\n             min = 0,\n             max = 1,\n             value = .65,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi2\",\n             \"Pr√§zision Hypothese 2\",\n             min = 2,\n             max = 100,\n             value = 13,\n             step = 1\n           )),\n           card(plotOutput(\"prior2\", height = \"200px\"))\n         ))), \n layout_column_wrap(\n  card(card_header(class = \"bg-dark\", \"Daten\"),\n     numericInput(\n                \"prog9\",\n                \"n‚ÇÅ = Bef√ºrwortung G9\",\n                min = 0,\n                value = 5,\n                step = 1),\n     numericInput(\n                \"prog8\",\n                \"n‚ÇÇ = Bef√ºrwortung G8\",\n                min = 0,\n                value = 12,\n                step = 1)\n           ), \n  card(card_header(\"Likelihoods und Bayes Factor\", class = \"bg-dark\"),\n       card_body(shinycssloaders::withSpinner(plotOutput(\"plot\"), color = \"#1bbc9d\")\n))\n))\n\n\n\nserver &lt;- function(input, output, session) {\n\n################################################################################\n### Plot of Priors                                                           ###\n################################################################################\n\n\n### custom functions ###########################################################\n# muphi_to_shapes \nmuphi_to_shapes &lt;- function(mu, phi) {\n  shape1 &lt;- mu * phi\n  shape2 &lt;- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n### aux variables ##############################################################\n# convert prior parameterization\n\nprior_shapes1 &lt;- reactive({\n  muphi_to_shapes(input$prior_mu1, input$prior_phi1)\n})\n\nprior_shapes2 &lt;- reactive({\n  muphi_to_shapes(input$prior_mu2, input$prior_phi2)\n})\n\n### Plot Prior 1 ###############################################################\noutput$prior1 &lt;- renderPlot({\n\n  p &lt;- seq(0,1, length=1000)\n\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes1()$shape1,\n          prior_shapes1()$shape2),\n    type = 'l',\n    col = \"#bc1b9a\",\n    ylab = \"W'keitsdichte\",\n    xlab = \"Anteil G9-Bef√ºrworter:innen\",\n    frame.plot = F\n    )\n}\n)\n\n### Plot Prior 2 ###############################################################\noutput$prior2 &lt;- renderPlot({\n\n  p &lt;- seq(0,1, length=1000)\n\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes2()$shape1,\n          prior_shapes2()$shape2),\n    type = 'l',\n    col = \"#bc991b\",\n    ylab = \"W'keitsdichte\",\n    xlab = \"Anteil G9-Bef√ºrworter:innen\",\n    frame.plot = F\n    )\n}\n)\n\n\n################################################################################\n### Plot of Likelihoods                                                      ###\n################################################################################\n\n### custom reactive values #####################################################\nN &lt;- reactive({input$prog8 + input$prog9})\n\n\n### compute the bf from marginal likelihoods ##################################\nwkeit1 &lt;- reactive({\n  integral(likelihood(family = \"binomial\", \n                      successes = input$prog9, \n                      trials = input$prog9 + input$prog8)*\n              prior(family = \"beta\", \n                  alpha = prior_shapes1()$shape1, \n                  beta = prior_shapes1()$shape2))\n})\n\nwkeit2 &lt;- reactive({ \n  integral(likelihood(family = \"binomial\", \n                      successes = input$prog9, \n                      trials = input$prog9 + input$prog8)*\n              prior(family = \"beta\", \n                  alpha = prior_shapes2()$shape1, \n                  beta = prior_shapes2()$shape2))\n})\n\n### create data for the two marginal likelihood distributions ####################\ndata &lt;- reactive({\n\ndata_h1 &lt;- tibble(k = 1:N(),\n                  hyp = \"Hypothese 1\")\nfor(i in 1:N()){\ndata_h1$p[i] &lt;- integral(likelihood(family = \"binomial\", \n                         successes = data_h1$k[i], \n                         trials = input$prog9 + input$prog8)*\n                   prior(family = \"beta\", \n                         alpha = prior_shapes1()$shape1, \n                         beta = prior_shapes1()$shape2))\n}\n\ndata_h1 &lt;- data_h1 %&gt;% \n  mutate(obs_eq_k = k == N()) \n\n\ndata_h2 &lt;- tibble(k = 1:N(),\n                  hyp = \"Hypothese 2\")\nfor(i in 1:N()){\ndata_h2$p[i] &lt;- integral(likelihood(family = \"binomial\", \n                         successes = data_h2$k[i], \n                         trials = input$prog9 + input$prog8)*\n                   prior(family = \"beta\", \n                         alpha = prior_shapes2()$shape1, \n                         beta = prior_shapes2()$shape2))\n}\n\ndata_h2 &lt;- data_h2 %&gt;% \n  mutate(obs_eq_k = k == N()) \n\n\n\nreturn(full_join(data_h1, data_h2))\n\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n\n ggplot() +\n    # add whole binomial distributions with alpha\n    geom_segment(data = data() %&gt;% \n                          filter(hyp == \"Hypothese 1\"), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p), \n                 color = \"#bc1b9a50\") +\n    geom_segment(data = data() %&gt;% \n                     filter(hyp == \"Hypothese 2\"), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p), \n                 color = \"#bc991b60\") +\n    # add selected binomial distributions without alpha\n    geom_segment(data = data() %&gt;% \n                     filter(hyp == \"Hypothese 1\" & k == input$prog9), \n                 aes(x = k - .1, xend = k -.1, y = 0, yend = p, color = \"#bc1b9a\")) +\n    geom_segment(data = data() %&gt;% \n                     filter(hyp == \"Hypothese 2\" & k == input$prog9), \n                 aes(x = k + .1, xend = k +.1, y = 0, yend = p, color = \"#bc991b\")) +\n    theme_minimal() +\n    geom_text(data = tibble(x = input$prog9, y = -.005, \n                            text = paste(\"BF =\", \n                                         formatC(wkeit1()/wkeit2(), \n                                                 format = \"e\", \n                                                 digits = 2))),\n              aes(x, y, label = text)) +\n    xlab(\"Anzahl\") + ylab(\"Wahrscheinlichkeit\") +\n    ggtitle(\"Berechnung des Bayes-Faktors\", \"bei Punkthypothesen\") +\n    scale_color_identity(name = \"Marginal Likelihood\",\n                         breaks = c(\"#bc1b9a\", \"#bc991b\"),\n                         labels = c(\"Hyp. 1\", \"Hyp 2.\"),\n                         guide = \"legend\") +\n    theme(legend.position = \"bottom\")\n})\n\n### debug ######################################################################\noutput$debug &lt;- renderPrint({\n data()\n})\n\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\nBuergler, S., Sezer, D., Bagge, N., Kirsch, I., Locher, C., Carvalho, C., & Gaab, J. (2023). Imaginary Pills and Open-Label Placebos Can Reduce Test Anxiety by Means of Placebo Mechanisms  Scientific Reports. Scientific Reports, 13(1), 2624.\n\n\nD√∂ring, N., & Bortz, J. (2016). Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften (5., vollst). Berlin, Heidelberg: Springer.\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik Und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\n\n\nGu, X., Hoijtink, H., Mulder, J., & Rosseel, Y. (2019). Bain: A Program for Bayesian Testing of Order Constrained Hypotheses in Structural Equation Models. Journal of Statistical Computation and Simulation, 89(8), 1526‚Äì1553.\n\n\nHoijtink, H. (2012). Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists. Boca Raton: CRC.\n\n\nKruschke, J. K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd Aufl.). Academic Press.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis Testing, Estimation, Meta-Analysis, and Power Analysis from a Bayesian Perspective. Psychonomic Bulletin & Review, 25, 178‚Äì206.\n\n\nLakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses. Social Psychological and Personality Science, 8(4), 355‚Äì362.\n\n\nTendeiro, J. N., Kiers, H. A. L., Hoekstra, R., Wong, T. K., & Morey, R. D. (2024). Diagnosing the Misuse of the Bayes Factor in Applied Research. Advances in Methods and Practices in Psychological Science, 7(1), 25152459231213371.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Hypothesen testen vs. Parameter sch√§tzen</span>"
    ]
  },
  {
    "objectID": "fully_bayesian_estimation.html",
    "href": "fully_bayesian_estimation.html",
    "title": "3¬† The (Fully) Bayesian Estimation Aproach",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 800\n\nlibrary(bslib)\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Prior\"),\n         card_body(\n           sliderInput(\n             \"prior_mu\",\n             \"Prior Mean\",\n             min = 0,\n             max = 1,\n             value = .5,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi\",\n             \"Prior Precision\",\n             min = 2,\n             max = 100,\n             value = 3,\n             step = 1\n           )\n         )),\n    card(card_header(class = \"bg-dark\", \"Data\"),\n         card_body(\n           numericInput(\n             \"successes\",\n             \"n‚ÇÅ = Zustimmung G9\",\n             min = 0,\n             value = 13,\n             step = 1\n           ),\n           numericInput(\n             \"failures\",\n             \"n‚ÇÇ = Ablehnung G9\",\n             min = 0,\n             value = 8,\n             step = 1\n           )\n         ))), \n  card(card_header(\"Posterior\", class = \"bg-dark\"),\n       card_body(plotOutput(\"plot\")))\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n### custom functions ###########################################################\n# muphi_to_shapes \nmuphi_to_shapes &lt;- function(mu, phi) {\n  shape1 &lt;- mu * phi\n  shape2 &lt;- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n### aux variables ##############################################################\n# convert prior parameterization\n\nprior_shapes &lt;- reactive({\n  muphi_to_shapes(input$prior_mu, input$prior_phi)\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n  \n  # set x-axis\n  p &lt;- seq(0,1, length=1000)\n  \n  # compute max-desity for ylim and legend position\n  density_max &lt;-\n    max(c(\n      dbeta(p,\n            prior_shapes()$shape1,\n            prior_shapes()$shape2),\n      dbeta(\n        p,\n        prior_shapes()$shape1 + input$successes,\n        prior_shapes()$shape2 + input$failures\n      )\n    ))\n  \n  # compute lower bound of 96%-HPDI\n  hpdi_lb &lt;-\n    qbeta(.02,\n           prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  # compute upper bound of 96%-HPDI\n  hpdi_ub &lt;-\n    qbeta(.98,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  \n  # create plot\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes()$shape1,\n          prior_shapes()$shape2),\n    type = 'l',\n    col = \"#1bbc9d\",\n    ylab = \"Wahrscheinlichkeitsdichte\",\n    xlab = \"Anteil G9-Bef√ºrworter:innen\",\n    frame.plot = F,\n    ylim = c(0, density_max)\n    )\n  lines(p,\n        dbeta(\n          p,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures\n          ),\n          col = '#EA80FC'\n        )\n  polygon(c(hpdi_lb, hpdi_lb, hpdi_ub, hpdi_ub),\n          c(0, density_max/40, density_max/40, 0),\n          col = \"#EA80FC30\",\n          border = \"#EA80FC00\")\n  legend(\n    bty = \"n\",\n    .8,\n    density_max,\n    c('Prior', 'Posterior', '96% HPDI'),\n    lty = c(1, 1, 1),\n    lwd = c(1, 1, 8),\n    col = c('#1bbc9d', '#EA80FC', '#EA80FC30')\n  )\n\n})\n\n### debug ######################################################################\n# output$debug &lt;- renderPrint({\n#   max(c(\n#                dbeta(p, \n#                      prior_shapes()$shape1, \n#                      prior_shapes()$shape2),\n#                dbeta(p, \n#                      prior_shapes()$shape1 + input$successes, \n#                      prior_shapes()$shape2 + input$failures))\n#              )\n#              \n# })\n\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>The (Fully) Bayesian Estimation Aproach</span>"
    ]
  }
]