# Grundlegende Begriffe

## Wahrscheinlichkeitsbegriff von Laplace
Die mathematische Wahrscheinlichkeitstheorie (Stochastik) ist ein vergleichsweise junge Subdisziplin, die erst zu Beginn des 20. Jahrhunderts axiomatisch formalisiert wurde. in diesen AnsÃ¤tzen definiert man *WahrscheinlichkeitsmaÃŸe* z.B. durch die folgenden Axiome.  
Das ist weder besonders intuitiv noch hilfreich fÃ¼r die Anwendung in der Datenanalyse. Eine wichtige Kontextinfromation kÃ¶nnte jedoch sein, dass die Wahrscheinlichkeits*rechnung* bis ins 19. Jhd. hinein vor allem als Hilfsmittel fÃ¼r GlÃ¼cksspiele und Wetten entwickelt wurde. In diesem Kontext ist es recht hilfreich und intuitiv Wahrscheinlichkeit als relative HÃ¤ufigkeit zu verstehen. So findet man auch etwa in MathematikbÃ¼chern der 7.ten Klasse Aussagen wie 

> "Die Wahrscheinlichkeit, dass eine gerade Zahl gewÃ¼rfelt wird, betrÃ¤gt 3/6, denn es gibt 6 mÃ¶gliche Ergebnisse und drei gÃ¼nstige."

## Stochastik vs. Statistik
Infolge dessen waren dann viele Mathematiker:innen daran interessiert bei welchen Spielen mit welche Strategien mit welcher Wahrscheinlichkeit welcher Erfolg eintritt. Also zum Beispiel beim Roulette: Ich starte mit 10.000â‚¬ und setze immer 100â‚¬ + die Gewinne aus den Vorrunden auf Rot. Wie wahrscheinlich ist es, dass ich in 100 Runden 20.000â‚¬ habe? Wie wahrscheinlich ist es, dass ich nach 100 Runden pleite bin?
Die Berechnung der Wahrscheinlichkeit solcher real einretender Szenarien (= Daten) kann man anstellen, **weil man die Wahrscheinlichekit der Elementarereignisse (Rot, Schwarz, GrÃ¼n) kennt**. Das ist das kerninteresse der Stochastik.

Die Statistik hingegen interessiert sich fÃ¼r die umgekehrte Frage: **Wenn ich die Beobachtungen (Daten) habe, was kann ich dann Ã¼ber die Wahrscheinlichkeiten der Elementarereignisse sagen?**

## Bayesianischer Wahrscheinlichkeitsbegriff
Wenn es sich bei den Elementarereignissen nicht um GlÃ¼cksspiele handelt, kann die relative HÃ¤ufigkeit etwas kontraintuitiv sein: Wenn die Wahrscheinlichkeit einer Befragung ergibt, dass Donald J. Trump ğŸŠ mit 54% Wahrscheinlichkeit eine neue Amtszeit bekommt, dann ist die Interpretation, dass er in 54 von 100 FÃ¤llen gewinnt nicht besonders hilfreich. Vielmehr ist die Wahrscheinlichkeit dann eine Aussage Ã¼ber die Unsicherheit, die wir haben, wenn wir aufgrund der Daten Schlussfolgerungen Ã¼ber den die Daten generierenden Mechanismus treffen wollen. Die 54% wÃ¼rden dann also als *Â»ziemlich genau in der Mitte von **unmÃ¶glich** und **sicherÂ«*** interpretiert werden.


## Bayes Theorem
Bayes Theorem ist ein stochastischer Satz der eine bedingte Wahrscheinlichkeit $P(A|B)$ zur bedingten Wahrscheinlichkeit $P(B|A)$ in die andere Richtung umrechnet.  
 $P(A|B)$ ist dabei schulmathematisch als *Â»Die Wahrscheinlichkeit dass A eintritt unter der Annahme, dass B bereits eingetreten istÂ«* zu verstehen.
 
> Beispiel: Es liegen in einer Urne 2 blaue und vier grÃ¼ne Kugeln, ich ziehe zwei Kugeln ohne zurÃ¼cklegen.  
Ist das Ereignis $A$ = *Â»Blaue Kugel im ersten ZugÂ«*, $B$ = *Â»grÃ¼ne Kugel im ersten ZugÂ«* und $C$ = *Â»grÃ¼ne Kugel im zweiten ZugÂ«* dann ist $P(C|A) = 4/5$ und $P(C|B) = 3/5$ 
 
### Dynamische Veranschaulichung
Die beste dynamische Visualisierung zur ErklÃ¤rung des Bayes Theorems, die ich kenne, ist die folgende:
{{< video https://youtu.be/HZGCoVF3YvM?si=0UGmZC_T2966oYpH width="450" height="250" >}}

Gefragt wird ja zu Beginn nach $P(\text{librarian}|\text{meek\;and\;tidy\;soul})$ welche unter Verwendung der Wahrscheinlichkeit $P(\text{meek\;and\;tidy\;soul}|\text{librarian})$ berechnet wird.  
Verallgemeinert kann man sagen dass Bayes Theorem die Wahrscheinlichkeit $P(\text{Hypothesis}|\text{Data})$ unter Verwendung der Wahrscheinlichkeit $P(\text{Data}|\text{Hypothesis})$ mit folgender Formel berechnet:

$$
{\overbracket[0.25pt]{P (\text{Hypothesis} \mid \text{Data})}^{\text{Posterior}}} = \frac
{{\overbracket[0.25pt]{P (\text{Hypothesis})}^{\text{Prior}}} \times
{\overbracket[0.25pt]{P (\text{Data} \mid \text{Hypothesis})}^{\text{Likelihood}}}}
{{\underbracket[0.25pt]{{P(\text{E})}}_{\text{Average likelihood}}}}
$$


Im YouTube-Beispiel haben wir gesehen wie Bayes Theorem auf ein Modell angewendet wird, das wir uns als Urne mit Kugeln zweier Farben vorstellen kÃ¶nnen, wobei eine Farbe Farmer und eien Farbe Librarians enkodiert.  
In der Regressionsmodellierung wird Bayes Theorem benutzt um die Parameter eines Regressionsmodells zu spezifizieren. Nehmen wir an wir wollen modellieren mit welcher Vorbereitungszeit welcher Erfolg in einer Klausur einhergeht, kÃ¶nnten Prior (Predictions), Data & Likelihood sowie Posterior (Predictions) wie folgt aussehen:

![Beispiel einer Bayesian Beta-Regression](img/Beta_Bayes.png){}
Bevor wir uns aber anschauen wie wir zu diesen Posterior-Verteilungen kommen, schauen wir uns nochmal die grundlegende Unterscheidung Inferenz- und Deskriptivstatistik sowie zwischen SchÃ¤tzung und Testung an.